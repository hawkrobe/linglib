import Linglib.Core.Softmax.Basic
import Mathlib.Order.Filter.Basic
import Mathlib.Topology.Order.Basic
import Mathlib.Topology.Order.Real
import Mathlib.Analysis.SpecialFunctions.Pow.Real
import Mathlib.Analysis.SpecialFunctions.Log.Deriv
import Mathlib.Topology.Algebra.InfiniteSum.Real

/-!
# Softmax Function: Limit Behavior

Î± â†’ 0: uniform, Î± â†’ âˆ: argmax, Î± â†’ -âˆ: argmin.
-/

namespace Softmax

open Real BigOperators Finset Filter Topology

variable {Î¹ : Type*} [Fintype Î¹] [DecidableEq Î¹]

/-- The set of indices achieving the maximum score. -/
def argmaxSet (s : Î¹ â†’ â„) : Set Î¹ :=
  {i | âˆ€ j, s j â‰¤ s i}

/-- The set of indices achieving the minimum score. -/
def argminSet (s : Î¹ â†’ â„) : Set Î¹ :=
  {i | âˆ€ j, s i â‰¤ s j}

/-- Maximum score value. -/
noncomputable def maxScore [Nonempty Î¹] (s : Î¹ â†’ â„) : â„ :=
  â¨† i, s i

/-- Minimum score value. -/
noncomputable def minScore [Nonempty Î¹] (s : Î¹ â†’ â„) : â„ :=
  â¨… i, s i

/-- Fact 4: As Î± â†’ 0, softmax converges to uniform distribution. -/
theorem tendsto_softmax_zero [Nonempty Î¹] (s : Î¹ â†’ â„) (i : Î¹) :
    Tendsto (fun Î± => softmax s Î± i) (ğ“ 0) (ğ“ (1 / Fintype.card Î¹)) := by
  have h : softmax s 0 i = 1 / Fintype.card Î¹ := by
    have := softmax_zero s
    simp only [this]
  rw [â† h]
  apply Continuous.tendsto
  -- softmax Î± i = exp(Î± * s i) / Î£â±¼ exp(Î± * s j) is continuous in Î±
  -- Numerator: exp is continuous, mul is continuous
  -- Denominator: finite sum of continuous functions, always positive
  simp only [softmax]
  apply Continuous.div
  Â· exact continuous_exp.comp (continuous_mul_right (s i))
  Â· apply continuous_finset_sum
    intro j _
    exact continuous_exp.comp (continuous_mul_right (s j))
  Â· intro Î±
    exact partitionFn_ne_zero s Î±

/-- The ratio of non-max to max probability vanishes as Î± â†’ âˆ. -/
theorem softmax_ratio_tendsto_zero [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i j : Î¹) (hij : s i < s j) :
    Tendsto (fun Î± => softmax s Î± i / softmax s Î± j) atTop (ğ“ 0) := by
  simp only [softmax_odds]
  -- exp(Î± * (s_i - s_j)) â†’ 0 when s_i < s_j
  have h : s i - s j < 0 := by linarith
  -- Use Mathlib: exp(x) â†’ 0 as x â†’ -âˆ, and c * Î± â†’ -âˆ when c < 0
  have hconv : Tendsto (fun Î± => (s i - s j) * Î±) atTop atBot :=
    tendsto_id.const_mul_atTop_of_neg h
  -- Rewrite to match: Î± * (s i - s j) = (s i - s j) * Î±
  have heq : (fun Î± => exp (Î± * (s i - s j))) = (fun Î± => exp ((s i - s j) * Î±)) := by
    ext Î±; ring_nf
  rw [heq]
  exact tendsto_exp_atBot.comp hconv

/-- At the maximum, softmax â†’ 1 as Î± â†’ âˆ. Helper lemma. -/
theorem tendsto_softmax_infty_at_max [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_unique : âˆ€ j, j â‰  i_max â†’ s j < s i_max) :
    Tendsto (fun Î± => softmax s Î± i_max) atTop (ğ“ 1) := by
  -- Simple proof: softmax sums to 1, and all non-max terms â†’ 0
  -- So: softmax_max = 1 - Î£_{jâ‰ max} softmax_j â†’ 1 - 0 = 1
  set S := Finset.univ.filter (fun j : Î¹ => j â‰  i_max) with hS
  have hsum : âˆ€ Î±, softmax s Î± i_max = 1 - âˆ‘ j âˆˆ S, softmax s Î± j := by
    intro Î±
    have h := softmax_sum_eq_one s Î±
    rw [â† Finset.sum_filter_add_sum_filter_not (s := Finset.univ) (p := (Â· = i_max))] at h
    have hsimp : Finset.filter (Â· = i_max) Finset.univ = {i_max} := by
      ext x
      simp only [Finset.mem_filter, Finset.mem_univ, true_and, Finset.mem_singleton]
    rw [hsimp, Finset.sum_singleton] at h
    have hne : Finset.filter (fun x => Â¬x = i_max) Finset.univ = S := by
      ext x
      simp only [Finset.mem_filter, Finset.mem_univ, true_and, ne_eq, hS]
    rw [hne] at h
    linarith
  -- First show each softmax_j â†’ 0 for j â‰  max
  have heach : âˆ€ j âˆˆ S, Tendsto (fun Î± => softmax s Î± j) atTop (ğ“ 0) := by
    intro j hj
    rw [hS, Finset.mem_filter] at hj
    -- softmax_j â‰¤ (softmax_j / softmax_max) because softmax_max â‰¤ 1
    have hratio := softmax_ratio_tendsto_zero s j i_max (h_unique j hj.2)
    have hbound : âˆ€ Î±, softmax s Î± j â‰¤ softmax s Î± j / softmax s Î± i_max := by
      intro Î±
      have h1 : softmax s Î± i_max â‰¤ 1 := softmax_le_one s Î± i_max
      have hpos : 0 < softmax s Î± i_max := softmax_pos s Î± i_max
      have hinv : 1 â‰¤ 1 / softmax s Î± i_max := (one_le_div hpos).mpr h1
      calc softmax s Î± j = softmax s Î± j * 1 := by ring
        _ â‰¤ softmax s Î± j * (1 / softmax s Î± i_max) :=
            mul_le_mul_of_nonneg_left hinv (softmax_nonneg s Î± j)
        _ = softmax s Î± j / softmax s Î± i_max := by ring
    exact tendsto_of_tendsto_of_tendsto_of_le_of_le tendsto_const_nhds hratio
      (fun Î± => softmax_nonneg s Î± j) hbound
  -- Sum of terms each â†’ 0 is â†’ 0
  have hsum_zero : Tendsto (fun Î± => âˆ‘ j âˆˆ S, softmax s Î± j) atTop (ğ“ 0) := by
    have h := tendsto_finset_sum S (fun j hj => heach j hj)
    simp only [Finset.sum_const_zero] at h
    exact h
  -- 1 - sum â†’ 1 - 0 = 1
  have hmain : Tendsto (fun Î± => 1 - âˆ‘ j âˆˆ S, softmax s Î± j) atTop (ğ“ (1 : â„)) := by
    have htend : Tendsto (fun Î± => (1 : â„) - âˆ‘ j âˆˆ S, softmax s Î± j) atTop (ğ“ ((1 : â„) - 0)) :=
      tendsto_const_nhds.sub hsum_zero
    simp only [sub_zero] at htend
    exact htend
  exact hmain.congr (fun Î± => (hsum Î±).symm)

/-- When there's a unique maximum, softmax concentrates on it as Î± â†’ âˆ. -/
theorem tendsto_softmax_infty_unique_max [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_unique : âˆ€ j, j â‰  i_max â†’ s j < s i_max) (i : Î¹) :
    Tendsto (fun Î± => softmax s Î± i) atTop
      (ğ“ (if i = i_max then 1 else 0)) := by
  by_cases h : i = i_max
  Â· -- i = i_max, so we need softmax â†’ 1
    rw [if_pos h, h]
    exact tendsto_softmax_infty_at_max s i_max h_unique
  Â· -- i â‰  i_max, so we need softmax â†’ 0
    rw [if_neg h]
    have hi : s i < s i_max := h_unique i h
    have hratio := softmax_ratio_tendsto_zero s i i_max hi
    have hbound : âˆ€ Î±, softmax s Î± i â‰¤ softmax s Î± i / softmax s Î± i_max := by
      intro Î±
      have h1 : softmax s Î± i_max â‰¤ 1 := softmax_le_one s Î± i_max
      have hpos : 0 < softmax s Î± i_max := softmax_pos s Î± i_max
      have hinv : 1 â‰¤ 1 / softmax s Î± i_max := (one_le_div hpos).mpr h1
      calc softmax s Î± i = softmax s Î± i * 1 := by ring
        _ â‰¤ softmax s Î± i * (1 / softmax s Î± i_max) :=
            mul_le_mul_of_nonneg_left hinv (softmax_nonneg s Î± i)
        _ = softmax s Î± i / softmax s Î± i_max := by ring
    exact tendsto_of_tendsto_of_tendsto_of_le_of_le tendsto_const_nhds hratio
      (fun Î± => softmax_nonneg s Î± i) hbound

/-- Log-probability difference grows unboundedly. -/
theorem log_softmax_ratio_tendsto [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i j : Î¹) (hij : s i < s j) :
    Tendsto (fun Î± => log (softmax s Î± j / softmax s Î± i)) atTop atTop := by
  simp only [log_softmax_odds]
  -- Î± * (s_j - s_i) â†’ âˆ when s_j > s_i
  have h : 0 < s j - s i := by linarith
  -- Rewrite: Î± * (s j - s i) = (s j - s i) * Î±
  have heq : (fun Î± => Î± * (s j - s i)) = (fun Î± => (s j - s i) * Î±) := by
    ext Î±; ring
  rw [heq]
  exact tendsto_id.const_mul_atTop h

/-- As Î± â†’ -âˆ, softmax concentrates on the minimum. -/
theorem tendsto_softmax_neg_infty_unique_min [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_min : Î¹) (h_unique : âˆ€ j, j â‰  i_min â†’ s i_min < s j) (i : Î¹) :
    Tendsto (fun Î± => softmax s Î± i) atBot
      (ğ“ (if i = i_min then 1 else 0)) := by
  -- Use: softmax(s, Î±) = softmax(-s, -Î±)
  -- As Î± â†’ -âˆ, this is like softmax(-s, Î²) as Î² â†’ âˆ
  -- And -s has unique max at i_min (where s has unique min)
  have hconv : âˆ€ Î±, softmax s Î± = softmax (fun j => -s j) (-Î±) := by
    intro Î±
    funext j
    simp only [softmax]
    congr 1
    Â· congr 1; ring
    Â· apply Finset.sum_congr rfl; intro k _; congr 1; ring
  simp_rw [hconv]
  have hneg : âˆ€ j, j â‰  i_min â†’ -s j < -s i_min := by
    intro j hj
    exact neg_lt_neg (h_unique j hj)
  have := tendsto_softmax_infty_unique_max (fun j => -s j) i_min hneg i
  exact this.comp tendsto_neg_atBot_atTop

/-- The IBR limit: hardmax selector. -/
noncomputable def hardmax [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_unique : âˆ€ j, j â‰  i_max â†’ s j < s i_max) : Î¹ â†’ â„ :=
  fun i => if i = i_max then 1 else 0

/-- Softmax converges to hardmax as Î± â†’ âˆ (when maximum is unique). -/
theorem softmax_tendsto_hardmax [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_unique : âˆ€ j, j â‰  i_max â†’ s j < s i_max) :
    âˆ€ i, Tendsto (fun Î± => softmax s Î± i) atTop
      (ğ“ (hardmax s i_max h_unique i)) := by
  intro i
  simp only [hardmax]
  exact tendsto_softmax_infty_unique_max s i_max h_unique i

/-- Shannon entropy of a distribution. -/
noncomputable def entropy [Nonempty Î¹] (p : Î¹ â†’ â„) : â„ :=
  -âˆ‘ i : Î¹, p i * log (p i)

/-- Maximum possible entropy (uniform distribution). -/
noncomputable def maxEntropy (Î¹ : Type*) [Fintype Î¹] : â„ :=
  log (Fintype.card Î¹)

/-- As Î± â†’ 0, entropy of softmax approaches maximum. -/
theorem entropy_tendsto_max [Nonempty Î¹] (s : Î¹ â†’ â„) :
    Tendsto (fun Î± => entropy (softmax s Î±)) (ğ“ 0) (ğ“ (maxEntropy Î¹)) := by
  sorry

/-- As Î± â†’ âˆ (with unique max), entropy approaches 0. -/
theorem entropy_tendsto_zero [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_unique : âˆ€ j, j â‰  i_max â†’ s j < s i_max) :
    Tendsto (fun Î± => entropy (softmax s Î±)) atTop (ğ“ 0) := by
  sorry

/-- Exponential rate of concentration. -/
theorem softmax_exponential_decay [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_max : âˆ€ j, s j â‰¤ s i_max) (i : Î¹) (hi : s i < s i_max) :
    âˆƒ C > 0, âˆ€ Î± > 0, softmax s Î± i â‰¤ C * exp (-Î± * (s i_max - s i)) := by
  sorry

/-- For practical computation: when is softmax close enough to hardmax? -/
theorem softmax_negligible [Nonempty Î¹] (s : Î¹ â†’ â„)
    (i_max : Î¹) (h_max : âˆ€ j, s j â‰¤ s i_max) (Îµ : â„) (hÎµ : 0 < Îµ)
    (gap : â„) (hgap : 0 < gap) (h_gap_bound : âˆ€ j, j â‰  i_max â†’ s i_max - s j â‰¥ gap) :
    âˆ€ Î±, Î± > (1/gap) * |log Îµ| â†’
      âˆ€ j, j â‰  i_max â†’ softmax s Î± j < Îµ := by
  sorry

end Softmax
