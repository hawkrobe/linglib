import Mathlib.Analysis.SpecialFunctions.ExpDeriv
import Mathlib.Analysis.SpecialFunctions.Log.Basic
import Mathlib.Analysis.SpecialFunctions.Log.NegMulLog
import Mathlib.InformationTheory.KullbackLeibler.KLFun
import Mathlib.Data.Fintype.BigOperators
import Mathlib.Algebra.BigOperators.Field
import Mathlib.Analysis.Convex.Mul

/-!
# Rational Action

The mathematical foundation for all soft-rational agents: RSA speakers/listeners,
BToM agents, and decision-theoretic actors.

## Architecture

A `RationalAction` agent selects actions with probability proportional to a
non-negative score function ‚Äî the **Luce choice rule** (Luce 1959). This is the
unique choice rule satisfying IIA (independence of irrelevant alternatives):
the relative probability of two actions depends only on their scores.

The key mathematical results characterizing this choice rule are:

1. **Softmax** (¬ß2): The exponential parameterization `score = exp(Œ± ¬∑ utility)`
   gives `policy = softmax(utility, Œ±)`. This is the standard form in RSA.

2. **Gibbs Variational Principle** (¬ß3): Softmax uniquely maximizes
   `H(p) + Œ± ¬∑ ‚ü®p, s‚ü©` on the probability simplex. This is the mathematical
   foundation for RSA convergence (Zaslavsky et al. 2020).

3. **Maximum Entropy** (¬ß4): Softmax is the max-entropy distribution subject
   to an expected-utility constraint. Equivalently, it minimizes free energy
   (the Boltzmann distribution from statistical mechanics).

4. **Bayesian Optimality** (¬ß5): The Bayesian posterior maximizes expected
   log-likelihood. This is the listener half of RSA convergence.

## References

- Luce, R. D. (1959). Individual Choice Behavior.
- Franke, M. & Degen, J. (submitted). The softmax function.
- Cover, T. M. & Thomas, J. A. (2006). Elements of Information Theory.
- Zaslavsky, N., Hu, J., & Levy, R. (2020). A Rate-Distortion view of RSA.
-/

namespace Core

open Real BigOperators Finset

-- ============================================================================
-- ¬ß1. RationalAction: Score-Based Agents
-- ============================================================================

/-- A rational action agent: selects actions with probability ‚àù score(state, action).

This is the Luce choice rule (Luce 1959). The `score` function is unnormalized;
normalization to a proper distribution is derived (see `policy`).

Key instances:
- RSA L0: `score(u, w) = prior(w) ¬∑ meaning(u, w)`
- RSA S1: `score(w, u) = rpow(informativity(w, u), Œ±) ¬∑ exp(-Œ± ¬∑ cost(u))`
- BToM agent: `score(state, action) = exp(Œ≤ ¬∑ Q(state, action))`
-/
structure RationalAction (State Action : Type*) [Fintype Action] where
  /-- Unnormalized score: policy(a|s) ‚àù score(s, a). -/
  score : State ‚Üí Action ‚Üí ‚Ñù
  /-- Scores are non-negative. -/
  score_nonneg : ‚àÄ s a, 0 ‚â§ score s a

variable {S A : Type*} [Fintype A]

/-- Total score across all actions in a state (normalization constant). -/
noncomputable def RationalAction.totalScore (ra : RationalAction S A) (s : S) : ‚Ñù :=
  ‚àë a : A, ra.score s a

theorem RationalAction.totalScore_nonneg (ra : RationalAction S A) (s : S) :
    0 ‚â§ ra.totalScore s :=
  Finset.sum_nonneg fun a _ => ra.score_nonneg s a

/-- Normalized policy: P(a|s) = score(s,a) / Œ£_a' score(s,a').
    Returns 0 for all actions if totalScore = 0. -/
noncomputable def RationalAction.policy (ra : RationalAction S A) (s : S) (a : A) : ‚Ñù :=
  if ra.totalScore s = 0 then 0 else ra.score s a / ra.totalScore s

theorem RationalAction.policy_nonneg (ra : RationalAction S A) (s : S) (a : A) :
    0 ‚â§ ra.policy s a := by
  simp only [policy]
  split
  ¬∑ exact le_refl 0
  ¬∑ exact div_nonneg (ra.score_nonneg s a) (ra.totalScore_nonneg s)

/-- Policy sums to 1 when totalScore is nonzero. -/
theorem RationalAction.policy_sum_eq_one (ra : RationalAction S A) (s : S)
    (h : ra.totalScore s ‚â† 0) :
    ‚àë a : A, ra.policy s a = 1 := by
  simp only [policy, h, ‚ÜìreduceIte, ‚Üê Finset.sum_div]
  exact div_self h

/-- Policy monotonicity: higher score ‚Üí higher probability. -/
theorem RationalAction.policy_monotone (ra : RationalAction S A) (s : S)
    (a‚ÇÅ a‚ÇÇ : A) (h : ra.score s a‚ÇÅ ‚â§ ra.score s a‚ÇÇ) :
    ra.policy s a‚ÇÅ ‚â§ ra.policy s a‚ÇÇ := by
  simp only [policy]
  split
  ¬∑ exact le_refl 0
  ¬∑ next hne =>
    have hpos : 0 < ra.totalScore s :=
      lt_of_le_of_ne (ra.totalScore_nonneg s) (Ne.symm hne)
    exact div_le_div_of_nonneg_right h (le_of_lt hpos)

-- ============================================================================
-- ¬ß1a. Luce's Choice Axiom (IIA)
-- ============================================================================

/-!
## Luce's Choice Axiom

Luce (1959, Chapter 1) showed that the ratio rule `P(a|s) = v(a)/Œ£v(b)` is
characterized by the **independence of irrelevant alternatives** (IIA): the
relative probability of two actions depends only on their scores, not on what
other actions are available.

We formalize:
- The **constant ratio rule** (Theorem 2): `policy(a‚ÇÅ) ¬∑ score(a‚ÇÇ) = policy(a‚ÇÇ) ¬∑ score(a‚ÇÅ)`
- **Choice from subsets** (`pChoice`): restriction of the choice rule to a `Finset`
- **IIA** (Axiom 1): ratios in any subset equal score ratios
- The **product rule** (Theorem 1): `P(a,T) = P(a,S) ¬∑ P(S,T)` for `S ‚äÜ T`
- **Scale invariance** (Theorem 5): multiplying all scores by `k > 0` preserves policy
- **Uniqueness** (Theorem 4, forward): proportional scores yield the same policy
-/

section LuceChoiceAxiom

variable {S A : Type*} [Fintype A]

/-- Constant Ratio Rule (Luce 1959, Theorem 2):
    `policy(a‚ÇÅ) ¬∑ score(a‚ÇÇ) = policy(a‚ÇÇ) ¬∑ score(a‚ÇÅ)`.
    The odds ratio policy(a‚ÇÅ)/policy(a‚ÇÇ) = score(a‚ÇÅ)/score(a‚ÇÇ). -/
theorem RationalAction.policy_ratio (ra : RationalAction S A) (s : S) (a‚ÇÅ a‚ÇÇ : A) :
    ra.policy s a‚ÇÅ * ra.score s a‚ÇÇ = ra.policy s a‚ÇÇ * ra.score s a‚ÇÅ := by
  simp only [policy]
  split
  ¬∑ simp
  ¬∑ next hne =>
    field_simp

/-- Choice probability from a subset: `pChoice(a, T) = score(a) / Œ£_{b‚ààT} score(b)`.
    Returns 0 if `a ‚àâ T` or the subset total is 0. -/
noncomputable def RationalAction.pChoice [DecidableEq A] (ra : RationalAction S A) (s : S)
    (T : Finset A) (a : A) : ‚Ñù :=
  if a ‚àà T then
    let subTotal := ‚àë b ‚àà T, ra.score s b
    if subTotal = 0 then 0 else ra.score s a / subTotal
  else 0

/-- `pChoice` on the full set equals `policy`. -/
theorem RationalAction.pChoice_univ [DecidableEq A] (ra : RationalAction S A) (s : S) (a : A) :
    ra.pChoice s Finset.univ a = ra.policy s a := by
  simp only [pChoice, Finset.mem_univ, ‚ÜìreduceIte, policy, totalScore]

/-- `pChoice` is non-negative. -/
theorem RationalAction.pChoice_nonneg [DecidableEq A] (ra : RationalAction S A) (s : S)
    (T : Finset A) (a : A) :
    0 ‚â§ ra.pChoice s T a := by
  simp only [pChoice]
  split
  ¬∑ split
    ¬∑ exact le_refl 0
    ¬∑ next hne =>
      exact div_nonneg (ra.score_nonneg s a)
        (Finset.sum_nonneg fun b _ => ra.score_nonneg s b)
  ¬∑ exact le_refl 0

/-- `pChoice` sums to 1 over the subset when the subset total is nonzero. -/
theorem RationalAction.pChoice_sum_eq_one [DecidableEq A] (ra : RationalAction S A) (s : S)
    (T : Finset A) (hT : ‚àë b ‚àà T, ra.score s b ‚â† 0) :
    ‚àë a ‚àà T, ra.pChoice s T a = 1 := by
  simp only [pChoice]
  have : ‚àë a ‚àà T, (if a ‚àà T then if ‚àë b ‚àà T, ra.score s b = 0 then 0
      else ra.score s a / ‚àë b ‚àà T, ra.score s b else 0) =
      ‚àë a ‚àà T, (if ‚àë b ‚àà T, ra.score s b = 0 then 0
      else ra.score s a / ‚àë b ‚àà T, ra.score s b) := by
    apply Finset.sum_congr rfl
    intro a ha; simp [ha]
  rw [this]; simp only [hT, ‚ÜìreduceIte, ‚Üê Finset.sum_div]; exact div_self hT

/-- IIA core: the ratio of `pChoice` values in any subset equals the score ratio.
    For `a‚ÇÅ, a‚ÇÇ ‚àà T` with `score(a‚ÇÇ) > 0`:
    `pChoice(a‚ÇÅ, T) ¬∑ score(a‚ÇÇ) = pChoice(a‚ÇÇ, T) ¬∑ score(a‚ÇÅ)` (Luce 1959, Axiom 1). -/
theorem RationalAction.pChoice_ratio [DecidableEq A] (ra : RationalAction S A) (s : S)
    (T : Finset A) (a‚ÇÅ a‚ÇÇ : A) (h‚ÇÅ : a‚ÇÅ ‚àà T) (h‚ÇÇ : a‚ÇÇ ‚àà T) :
    ra.pChoice s T a‚ÇÅ * ra.score s a‚ÇÇ = ra.pChoice s T a‚ÇÇ * ra.score s a‚ÇÅ := by
  simp only [pChoice, h‚ÇÅ, h‚ÇÇ, ‚ÜìreduceIte]
  split
  ¬∑ simp
  ¬∑ next hne => field_simp

/-- Helper: `pChoice` value for `a ‚àà T` with nonzero total. -/
private theorem RationalAction.pChoice_mem [DecidableEq A] (ra : RationalAction S A) (s : S)
    (T : Finset A) (a : A) (ha : a ‚àà T) (hT : ‚àë b ‚àà T, ra.score s b ‚â† 0) :
    ra.pChoice s T a = ra.score s a / ‚àë b ‚àà T, ra.score s b := by
  simp only [pChoice, ha, hT, ‚ÜìreduceIte]

/-- IIA (Luce 1959, Axiom 1): `P(a, S) = P(a, T) / Œ£_{b‚ààS} P(b, T)` for `S ‚äÜ T`.
    Choice probability from a subset is the conditional probability. -/
theorem RationalAction.iia [DecidableEq A] (ra : RationalAction S A) (s : S)
    (S' T : Finset A) (hST : S' ‚äÜ T)
    (a : A) (ha : a ‚àà S')
    (hS_pos : ‚àë b ‚àà S', ra.score s b ‚â† 0)
    (hT_pos : ‚àë b ‚àà T, ra.score s b ‚â† 0) :
    ra.pChoice s S' a = ra.pChoice s T a / ‚àë b ‚àà S', ra.pChoice s T b := by
  rw [ra.pChoice_mem s S' a ha hS_pos, ra.pChoice_mem s T a (hST ha) hT_pos]
  have hsum : ‚àë b ‚àà S', ra.pChoice s T b =
      (‚àë b ‚àà S', ra.score s b) / ‚àë c ‚àà T, ra.score s c := by
    have : ‚àÄ b ‚àà S', ra.pChoice s T b = ra.score s b / ‚àë c ‚àà T, ra.score s c :=
      fun b hb => ra.pChoice_mem s T b (hST hb) hT_pos
    rw [Finset.sum_congr rfl this, Finset.sum_div]
  rw [hsum]
  field_simp

/-- Product rule (Luce 1959, Theorem 1):
    `P(a, T) = P(a, S) ¬∑ P(S, T)` for `a ‚àà S ‚äÜ T`,
    where `P(S, T) = Œ£_{b‚ààS} score(b) / Œ£_{b‚ààT} score(b)`. -/
theorem RationalAction.product_rule [DecidableEq A] (ra : RationalAction S A) (s : S)
    (S' T : Finset A) (hST : S' ‚äÜ T)
    (a : A) (ha : a ‚àà S')
    (hS_pos : ‚àë b ‚àà S', ra.score s b ‚â† 0)
    (hT_pos : ‚àë b ‚àà T, ra.score s b ‚â† 0) :
    ra.pChoice s T a =
    ra.pChoice s S' a * ((‚àë b ‚àà S', ra.score s b) / ‚àë b ‚àà T, ra.score s b) := by
  rw [ra.pChoice_mem s T a (hST ha) hT_pos, ra.pChoice_mem s S' a ha hS_pos]
  have hS_ne : (‚àë b ‚àà S', ra.score s b) ‚â† 0 := hS_pos
  rw [div_mul_div_comm, show ra.score s a * ‚àë b ‚àà S', ra.score s b =
      (‚àë b ‚àà S', ra.score s b) * ra.score s a from mul_comm _ _,
      mul_div_mul_left _ _ hS_ne]

/-- Scale all scores by a positive constant `k`. -/
noncomputable def RationalAction.scaleBy (ra : RationalAction S A) (k : ‚Ñù) (hk : 0 < k) :
    RationalAction S A where
  score s a := k * ra.score s a
  score_nonneg s a := mul_nonneg (le_of_lt hk) (ra.score_nonneg s a)

/-- Scale invariance (Luce 1959, Theorem 5): scaling scores by `k > 0` preserves policy. -/
theorem RationalAction.scaleBy_policy (ra : RationalAction S A) (s : S) (a : A)
    (k : ‚Ñù) (hk : 0 < k) :
    (ra.scaleBy k hk).policy s a = ra.policy s a := by
  simp only [policy, scaleBy, totalScore, ‚Üê Finset.mul_sum]
  have hk_ne : k ‚â† 0 := ne_of_gt hk
  by_cases hs0 : ‚àë a' : A, ra.score s a' = 0
  ¬∑ simp [hs0]
  ¬∑ have hne : k * ‚àë a' : A, ra.score s a' ‚â† 0 := mul_ne_zero hk_ne hs0
    simp [hs0, hne]
    field_simp

/-- Uniqueness (forward direction, Luce 1959, Theorem 4):
    If scores are proportional (`score'(s,a) = k ¬∑ score(s,a)` for some `k > 0`),
    then both agents have the same policy. -/
theorem RationalAction.policy_eq_of_proportional (ra ra' : RationalAction S A) (s : S)
    (k : ‚Ñù) (hk : 0 < k) (h : ‚àÄ a, ra'.score s a = k * ra.score s a) (a : A) :
    ra'.policy s a = ra.policy s a := by
  simp only [policy, totalScore]
  have hk_ne : k ‚â† 0 := ne_of_gt hk
  simp_rw [h, ‚Üê Finset.mul_sum]
  by_cases hs0 : ‚àë a' : A, ra.score s a' = 0
  ¬∑ simp [hs0]
  ¬∑ have hne : k * ‚àë a' : A, ra.score s a' ‚â† 0 := mul_ne_zero hk_ne hs0
    simp [hs0, hne]
    field_simp

end LuceChoiceAxiom

-- ============================================================================
-- ¬ß2. Softmax Function
-- ============================================================================

/-!
## Softmax Function

The softmax function `œÉ(s, Œ±)·µ¢ = exp(Œ± ¬∑ s·µ¢) / Œ£‚±º exp(Œ± ¬∑ s‚±º)` is the
exponential parameterization of the Luce choice rule. Following Franke & Degen
(submitted), we establish Facts 1‚Äì8.
-/

/-- The softmax function: softmax(s, Œ±)·µ¢ = exp(Œ± ¬∑ s·µ¢) / Œ£‚±º exp(Œ± ¬∑ s‚±º). -/
noncomputable def softmax {Œπ : Type*} [Fintype Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) : Œπ ‚Üí ‚Ñù :=
  Œª i => exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)

/-- The partition function (normalizing constant) Z = Œ£‚±º exp(Œ± ¬∑ s‚±º). -/
noncomputable def partitionFn {Œπ : Type*} [Fintype Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) : ‚Ñù :=
  ‚àë j : Œπ, exp (Œ± * s j)

/-- Log-sum-exp: log of partition function. -/
noncomputable def logSumExp {Œπ : Type*} [Fintype Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) : ‚Ñù :=
  log (‚àë j : Œπ, exp (Œ± * s j))

section SoftmaxBasic

variable {Œπ : Type*} [Fintype Œπ]

/-- The partition function is always positive. -/
theorem partitionFn_pos [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    0 < partitionFn s Œ± := by
  apply Finset.sum_pos
  ¬∑ intro i _; exact exp_pos _
  ¬∑ exact Finset.univ_nonempty

theorem partitionFn_ne_zero [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    partitionFn s Œ± ‚â† 0 :=
  ne_of_gt (partitionFn_pos s Œ±)

/-- Each softmax probability is positive. (Fact 1, part 1) -/
theorem softmax_pos [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i : Œπ) :
    0 < softmax s Œ± i := by
  simp only [softmax]
  exact div_pos (exp_pos _) (partitionFn_pos s Œ±)

/-- Softmax probabilities sum to 1. (Fact 1, part 2) -/
theorem softmax_sum_eq_one [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    ‚àë i : Œπ, softmax s Œ± i = 1 := by
  simp only [softmax]
  have h : ‚àë x : Œπ, exp (Œ± * s x) / ‚àë j : Œπ, exp (Œ± * s j) =
           (‚àë x : Œπ, exp (Œ± * s x)) / ‚àë j : Œπ, exp (Œ± * s j) := by
    rw [Finset.sum_div]
  rw [h]
  exact div_self (partitionFn_ne_zero s Œ±)

/-- Softmax is non-negative. -/
theorem softmax_nonneg [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i : Œπ) :
    0 ‚â§ softmax s Œ± i :=
  le_of_lt (softmax_pos s Œ± i)

/-- Softmax is at most 1. -/
theorem softmax_le_one [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i : Œπ) :
    softmax s Œ± i ‚â§ 1 := by
  have h := softmax_sum_eq_one s Œ±
  have hpos : ‚àÄ j, 0 ‚â§ softmax s Œ± j := Œª j => softmax_nonneg s Œ± j
  calc softmax s Œ± i
      ‚â§ ‚àë j : Œπ, softmax s Œ± j := Finset.single_le_sum (Œª j _ => hpos j) (Finset.mem_univ i)
    _ = 1 := h

/-- Fact 2: Odds are determined by score differences: p·µ¢/p‚±º = exp(Œ±(s·µ¢ - s‚±º)). -/
theorem softmax_odds [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i j : Œπ) :
    softmax s Œ± i / softmax s Œ± j = exp (Œ± * (s i - s j)) := by
  simp only [softmax]
  have hZ : (‚àë k : Œπ, exp (Œ± * s k)) ‚â† 0 := partitionFn_ne_zero s Œ±
  have hj : exp (Œ± * s j) ‚â† 0 := ne_of_gt (exp_pos _)
  field_simp
  have key : Œ± * s j + Œ± * (s i - s j) = Œ± * s i := by ring
  rw [‚Üê exp_add, key]

/-- Log-odds equal scaled score difference. -/
theorem log_softmax_odds [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i j : Œπ) :
    log (softmax s Œ± i / softmax s Œ± j) = Œ± * (s i - s j) := by
  rw [softmax_odds, log_exp]

/-- Ratio form of Fact 2. -/
theorem softmax_ratio [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i j : Œπ) :
    softmax s Œ± i = softmax s Œ± j * exp (Œ± * (s i - s j)) := by
  have h := softmax_odds s Œ± i j
  have hne : softmax s Œ± j ‚â† 0 := ne_of_gt (softmax_pos s Œ± j)
  field_simp at h ‚ä¢
  linarith [h]

/-- The logistic (sigmoid) function. -/
noncomputable def logistic (x : ‚Ñù) : ‚Ñù := 1 / (1 + exp (-x))

/-- Fact 3: For n = 2, softmax reduces to logistic. -/
theorem softmax_binary (s : Fin 2 ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    softmax s Œ± 0 = logistic (Œ± * (s 0 - s 1)) := by
  simp only [softmax, logistic, Fin.sum_univ_two]
  have key : Œ± * s 0 + (-(Œ± * (s 0 - s 1))) = Œ± * s 1 := by ring
  have h : exp (Œ± * s 0) + exp (Œ± * s 1) =
           exp (Œ± * s 0) * (1 + exp (-(Œ± * (s 0 - s 1)))) := by
    rw [mul_add, mul_one, ‚Üê exp_add, key]
  rw [h, ‚Üê div_div, div_self (ne_of_gt (exp_pos _))]

/-- Fact 6: Softmax is translation invariant. -/
theorem softmax_add_const (s : Œπ ‚Üí ‚Ñù) (Œ± c : ‚Ñù) :
    softmax (Œª i => s i + c) Œ± = softmax s Œ± := by
  funext i
  simp only [softmax]
  have hexp : ‚àÄ j, exp (Œ± * (s j + c)) = exp (Œ± * s j) * exp (Œ± * c) := by
    intro j; rw [‚Üê exp_add]; ring_nf
  simp_rw [hexp, ‚Üê Finset.sum_mul]
  rw [mul_div_mul_right _ _ (ne_of_gt (exp_pos _))]

/-- Fact 8: Multiplicative scaling can be absorbed into Œ±. -/
theorem softmax_scale (s : Œπ ‚Üí ‚Ñù) (Œ± a : ‚Ñù) (ha : a ‚â† 0) :
    softmax (Œª i => a * s i) (Œ± / a) = softmax s Œ± := by
  funext i
  simp only [softmax]
  congr 1
  ¬∑ congr 1; field_simp
  ¬∑ apply Finset.sum_congr rfl; intro j _; congr 1; field_simp

/-- Higher scores get higher probabilities (for Œ± > 0). -/
theorem softmax_mono [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) {Œ± : ‚Ñù} (hŒ± : 0 < Œ±) (i j : Œπ)
    (hij : s i ‚â§ s j) :
    softmax s Œ± i ‚â§ softmax s Œ± j := by
  simp only [softmax]
  apply div_le_div_of_nonneg_right _ (le_of_lt (partitionFn_pos s Œ±))
  apply exp_le_exp.mpr
  exact mul_le_mul_of_nonneg_left hij (le_of_lt hŒ±)

/-- Strict monotonicity. -/
theorem softmax_strict_mono [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) {Œ± : ‚Ñù} (hŒ± : 0 < Œ±)
    (i j : Œπ) (hij : s i < s j) :
    softmax s Œ± i < softmax s Œ± j := by
  simp only [softmax]
  apply div_lt_div_of_pos_right _ (partitionFn_pos s Œ±)
  apply exp_lt_exp.mpr
  exact mul_lt_mul_of_pos_left hij hŒ±

/-- At Œ± = 0, softmax is uniform. -/
theorem softmax_zero [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) :
    softmax s 0 = Œª _ => 1 / (Fintype.card Œπ : ‚Ñù) := by
  funext i
  simp only [softmax, zero_mul, exp_zero, Finset.sum_const, Finset.card_univ,
             nsmul_eq_mul, mul_one]

/-- For Œ± < 0, lower scores get higher probabilities. -/
theorem softmax_neg_mono [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) {Œ± : ‚Ñù} (hŒ± : Œ± < 0) (i j : Œπ)
    (hij : s i ‚â§ s j) :
    softmax s Œ± j ‚â§ softmax s Œ± i := by
  simp only [softmax]
  apply div_le_div_of_nonneg_right _ (le_of_lt (partitionFn_pos s Œ±))
  apply exp_le_exp.mpr
  exact mul_le_mul_of_nonpos_left hij (le_of_lt hŒ±)

/-- Log of softmax = score minus log partition function. -/
theorem log_softmax [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i : Œπ) :
    Real.log (softmax s Œ± i) = Œ± * s i - Real.log (partitionFn s Œ±) := by
  simp only [softmax, partitionFn]
  rw [Real.log_div (ne_of_gt (Real.exp_pos _)) (ne_of_gt (Finset.sum_pos
    (fun j _ => Real.exp_pos _) Finset.univ_nonempty))]
  rw [Real.log_exp]

/-- Softmax with default Œ± = 1. -/
noncomputable def softmax1 (s : Œπ ‚Üí ‚Ñù) : Œπ ‚Üí ‚Ñù := softmax s 1

/-- Temperature form: œÑ = 1/Œ±. -/
noncomputable def softmaxTemp (s : Œπ ‚Üí ‚Ñù) (œÑ : ‚Ñù) : Œπ ‚Üí ‚Ñù :=
  softmax s (1 / œÑ)

/-- Softmax is an exponential family distribution. -/
theorem softmax_exponential_family (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (i : Œπ) [Nonempty Œπ] :
    softmax s Œ± i = exp (Œ± * s i - logSumExp s Œ±) := by
  simp only [softmax, logSumExp]
  rw [exp_sub]
  have h : exp (log (‚àë j : Œπ, exp (Œ± * s j))) = ‚àë j : Œπ, exp (Œ± * s j) :=
    exp_log (partitionFn_pos s Œ±)
  rw [h]

end SoftmaxBasic

-- ============================================================================
-- ¬ß2a. RationalAction ‚Üî Softmax Bridge
-- ============================================================================

/-- Construct a RationalAction from a utility function via softmax.

The score is `exp(Œ± ¬∑ utility(s, a))`, so `policy = softmax(utility, Œ±)`. -/
noncomputable def RationalAction.fromSoftmax
    (utility : S ‚Üí A ‚Üí ‚Ñù) (Œ± : ‚Ñù) : RationalAction S A where
  score s a := exp (Œ± * utility s a)
  score_nonneg _ _ := le_of_lt (exp_pos _)

/-- The policy of a softmax agent equals the softmax function. -/
theorem RationalAction.fromSoftmax_policy_eq [Nonempty A]
    (utility : S ‚Üí A ‚Üí ‚Ñù) (Œ± : ‚Ñù) (s : S) (a : A) :
    (RationalAction.fromSoftmax utility Œ±).policy s a = softmax (utility s) Œ± a := by
  simp only [policy, fromSoftmax, totalScore, softmax]
  have hpos : 0 < ‚àë j : A, exp (Œ± * utility s j) := partitionFn_pos (utility s) Œ±
  have hne : ‚àë j : A, exp (Œ± * utility s j) ‚â† 0 := ne_of_gt hpos
  simp only [hne, ‚ÜìreduceIte]

-- ============================================================================
-- ¬ß3. KL Divergence and Gibbs Variational Principle
-- ============================================================================

/-!
## KL Divergence and the Gibbs Variational Principle

The softmax distribution uniquely maximizes entropy + expected score
on the probability simplex. This is the mathematical foundation for
RSA convergence (Zaslavsky et al. 2020, Proposition 1).

### Proof strategy

The Gibbs VP reduces to KL non-negativity via three identities:

1. H(p) + KL(p‚Äñq) = -‚àë p·µ¢ log q·µ¢          (negMulLog + KL term telescope)
2. -‚àë p·µ¢ log q·µ¢ = -Œ±‚ü®p,s‚ü© + log Z          (substitute log q·µ¢ = Œ± s·µ¢ - log Z)
3. H(q) + Œ±‚ü®q,s‚ü© = log Z                    (softmax self-information)

Combining: H(p) + Œ±‚ü®p,s‚ü© + KL = log Z = H(q) + Œ±‚ü®q,s‚ü©, so KL ‚â• 0 ‚üπ LHS ‚â§ RHS.

### References

- Cover & Thomas (2006), Elements of Information Theory, Ch. 2
- Zaslavsky et al. (2020), SM ¬ßB
-/

section KLDivergence

variable {Œπ : Type*} [Fintype Œπ]

/-- Finite KL divergence: KL(p ‚Äñ q) = Œ£ p·µ¢ ¬∑ log(p·µ¢ / q·µ¢).
    Convention: 0 ¬∑ log(0/q) = 0. -/
noncomputable def klFinite (p q : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë i, if p i = 0 then 0 else p i * Real.log (p i / q i)

/-- When q > 0, each KL term can be written via klFun:
    p ¬∑ log(p/q) = q ¬∑ klFun(p/q) + (p - q). -/
private theorem kl_term_eq_klFun {p_i q_i : ‚Ñù} (hq : 0 < q_i) (_hp : 0 ‚â§ p_i) :
    (if p_i = 0 then (0 : ‚Ñù) else p_i * log (p_i / q_i)) =
    q_i * InformationTheory.klFun (p_i / q_i) + (p_i - q_i) := by
  by_cases hp0 : p_i = 0
  ¬∑ simp only [hp0, ‚ÜìreduceIte, zero_div, InformationTheory.klFun_zero, mul_one, zero_sub,
               add_neg_cancel]
  ¬∑ simp only [hp0, ‚ÜìreduceIte]
    unfold InformationTheory.klFun
    have hq_ne : q_i ‚â† 0 := ne_of_gt hq
    field_simp
    ring

/-- Finite KL divergence equals Œ£ q·µ¢ ¬∑ klFun(p·µ¢/q·µ¢) when Œ£p·µ¢ = Œ£q·µ¢. -/
theorem kl_eq_sum_klFun (p q : Œπ ‚Üí ‚Ñù) (hq : ‚àÄ i, 0 < q i) (hp : ‚àÄ i, 0 ‚â§ p i)
    (hsum : ‚àë i, p i = ‚àë i, q i) :
    klFinite p q = ‚àë i, q i * InformationTheory.klFun (p i / q i) := by
  unfold klFinite
  have hterm : ‚àÄ i, (if p i = 0 then (0 : ‚Ñù) else p i * log (p i / q i)) =
      q i * InformationTheory.klFun (p i / q i) + (p i - q i) :=
    Œª i => kl_term_eq_klFun (hq i) (hp i)
  simp_rw [hterm]
  rw [Finset.sum_add_distrib]
  have hcancel : ‚àë i, (p i - q i) = 0 := by
    rw [Finset.sum_sub_distrib, hsum, sub_self]
  linarith

/-- **Gibbs' inequality (finite form)**: KL(p ‚Äñ q) ‚â• 0.

    For distributions p, q with q·µ¢ > 0, p·µ¢ ‚â• 0, and Œ£p·µ¢ = Œ£q·µ¢:
      Œ£·µ¢ p·µ¢ ¬∑ log(p·µ¢/q·µ¢) ‚â• 0

    Proof via Mathlib's `klFun_nonneg`: klFun(x) ‚â• 0 for x ‚â• 0. -/
theorem kl_nonneg (p q : Œπ ‚Üí ‚Ñù) (hq : ‚àÄ i, 0 < q i) (hp : ‚àÄ i, 0 ‚â§ p i)
    (hsum : ‚àë i, p i = ‚àë i, q i) :
    0 ‚â§ klFinite p q := by
  rw [kl_eq_sum_klFun p q hq hp hsum]
  apply Finset.sum_nonneg
  intro i _
  apply mul_nonneg (le_of_lt (hq i))
  exact InformationTheory.klFun_nonneg (div_nonneg (hp i) (le_of_lt (hq i)))

/-- Alternative KL non-negativity with distribution hypotheses. -/
theorem kl_nonneg' [Nonempty Œπ] {p q : Œπ ‚Üí ‚Ñù}
    (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hq_pos : ‚àÄ i, 0 < q i)
    (hp_sum : ‚àë i, p i = 1) (hq_sum : ‚àë i, q i = 1) :
    0 ‚â§ klFinite p q :=
  kl_nonneg p q hq_pos hp_nonneg (by rw [hp_sum, hq_sum])

end KLDivergence

-- ============================================================================
-- ¬ß3a. Gibbs Variational Principle
-- ============================================================================

section GibbsVariational

variable {Œπ : Type*} [Fintype Œπ]

/-- The per-meaning speaker objective: f(s) = Œ£·µ§ [negMulLog(s·µ§) + Œ± ¬∑ s·µ§ ¬∑ v·µ§].

This is the function that the speaker maximizes for each meaning m,
where v·µ§ = log L(m|u) is the listener utility of utterance u. -/
noncomputable def speakerObj (v : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (s : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë u, (Real.negMulLog (s u) + Œ± * s u * v u)

/-- The softmax achieves f(s*) = log Z, where Z is the partition function. -/
theorem speakerObj_at_softmax [Nonempty Œπ] (v : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    speakerObj v Œ± (softmax v Œ±) = logSumExp v Œ± := by
  unfold speakerObj logSumExp
  have hZ_pos : 0 < partitionFn v Œ± := partitionFn_pos v Œ±
  have hlog_softmax : ‚àÄ u, log (softmax v Œ± u) = Œ± * v u - log (partitionFn v Œ±) := by
    intro u
    simp only [softmax, partitionFn]
    rw [log_div (ne_of_gt (exp_pos _)) (ne_of_gt (Finset.sum_pos
      (fun j _ => exp_pos _) Finset.univ_nonempty)), log_exp]
  have hterm : ‚àÄ u, Real.negMulLog (softmax v Œ± u) + Œ± * softmax v Œ± u * v u =
      softmax v Œ± u * log (partitionFn v Œ±) := by
    intro u; unfold Real.negMulLog; rw [hlog_softmax]; ring
  simp_rw [hterm]
  rw [‚Üê Finset.sum_mul, softmax_sum_eq_one, one_mul]
  rfl

/-- Key identity: speakerObj(s) + KL(s ‚Äñ s*) = logSumExp (= speakerObj(s*)). -/
private theorem speakerObj_plus_kl [Nonempty Œπ] (v : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù)
    (s : Œπ ‚Üí ‚Ñù) (_hs_nonneg : ‚àÄ i, 0 ‚â§ s i) (hs_sum : ‚àë i, s i = 1) :
    speakerObj v Œ± s + klFinite s (softmax v Œ±) = logSumExp v Œ± := by
  unfold speakerObj klFinite logSumExp
  rw [‚Üê Finset.sum_add_distrib]
  have hZ_pos : 0 < ‚àë j : Œπ, exp (Œ± * v j) := partitionFn_pos v Œ±
  have hZ_ne : (‚àë j : Œπ, exp (Œ± * v j)) ‚â† 0 := ne_of_gt hZ_pos
  have hterm : ‚àÄ u, (Real.negMulLog (s u) + Œ± * s u * v u) +
      (if s u = 0 then (0 : ‚Ñù) else s u * log (s u / softmax v Œ± u)) =
      s u * log (‚àë j : Œπ, exp (Œ± * v j)) := by
    intro u
    by_cases hs0 : s u = 0
    ¬∑ simp [hs0, Real.negMulLog]
    ¬∑ simp only [hs0, ‚ÜìreduceIte]
      have hs_pos : 0 < softmax v Œ± u := softmax_pos v Œ± u
      rw [log_div hs0 (ne_of_gt hs_pos)]
      have hlog_sm : log (softmax v Œ± u) = Œ± * v u - log (‚àë j : Œπ, exp (Œ± * v j)) := by
        simp only [softmax]
        rw [log_div (ne_of_gt (exp_pos _)) (ne_of_gt (Finset.sum_pos
          (fun j _ => exp_pos _) Finset.univ_nonempty)), log_exp]
      rw [hlog_sm]; unfold Real.negMulLog; ring
  simp_rw [hterm, ‚Üê Finset.sum_mul, hs_sum, one_mul]

/-- **Gibbs Variational Principle**: softmax maximizes entropy + expected score.

For any distribution p on Œπ and scores s : Œπ ‚Üí ‚Ñù:
  H(p) + Œ±¬∑‚ü®p, s‚ü© ‚â§ H(q) + Œ±¬∑‚ü®q, s‚ü©
where q = softmax(s, Œ±) and H(p) = Œ£ negMulLog(p·µ¢). -/
theorem gibbs_variational [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (p : Œπ ‚Üí ‚Ñù)
    (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hp_sum : ‚àë i, p i = 1) :
    (‚àë i, Real.negMulLog (p i)) + Œ± * ‚àë i, p i * s i ‚â§
    (‚àë i, Real.negMulLog (softmax s Œ± i)) + Œ± * ‚àë i, softmax s Œ± i * s i := by
  set q := softmax s Œ±
  have hq_pos : ‚àÄ i, 0 < q i := fun i => softmax_pos s Œ± i
  have hq_sum : ‚àë i, q i = 1 := softmax_sum_eq_one s Œ±
  have hkl := kl_nonneg' hp_nonneg hq_pos hp_sum hq_sum
  have h_logq : ‚àÄ i, Real.log (q i) = Œ± * s i - logSumExp s Œ± := fun i => log_softmax s Œ± i
  have h_combine : ‚àÄ i,
      Real.negMulLog (p i) +
        (if p i = 0 then (0 : ‚Ñù) else p i * Real.log (p i / q i)) =
      -(p i * Real.log (q i)) := by
    intro i
    by_cases hpi : p i = 0
    ¬∑ simp [hpi, Real.negMulLog]
    ¬∑ simp only [hpi, ‚ÜìreduceIte, Real.negMulLog]
      have hpi_pos : 0 < p i := lt_of_le_of_ne (hp_nonneg i) (Ne.symm hpi)
      rw [Real.log_div (ne_of_gt hpi_pos) (ne_of_gt (hq_pos i))]
      ring
  have h1 : (‚àë i, Real.negMulLog (p i)) + klFinite p q =
      -(‚àë i, p i * Real.log (q i)) := by
    unfold klFinite
    rw [‚Üê Finset.sum_add_distrib]
    simp_rw [h_combine, Finset.sum_neg_distrib]
  have h2 : -(‚àë i, p i * Real.log (q i)) = -(Œ± * ‚àë i, p i * s i) + logSumExp s Œ± := by
    have : ‚àë i, p i * Real.log (q i) = Œ± * ‚àë i, p i * s i - logSumExp s Œ± := by
      simp_rw [h_logq]
      rw [show ‚àë i : Œπ, p i * (Œ± * s i - logSumExp s Œ±) =
          ‚àë i, (Œ± * (p i * s i) - logSumExp s Œ± * p i) from
        Finset.sum_congr rfl fun i _ => by ring]
      rw [Finset.sum_sub_distrib, ‚Üê Finset.mul_sum, ‚Üê Finset.mul_sum, hp_sum, mul_one]
    linarith
  have h3 : (‚àë i, Real.negMulLog (q i)) + Œ± * ‚àë i, q i * s i = logSumExp s Œ± := by
    rw [Finset.mul_sum, ‚Üê Finset.sum_add_distrib]
    rw [show ‚àë i : Œπ, (Real.negMulLog (q i) + Œ± * (q i * s i)) = ‚àë i, logSumExp s Œ± * q i from
      Finset.sum_congr rfl fun i _ => by simp only [Real.negMulLog, h_logq i]; ring]
    rw [‚Üê Finset.mul_sum, hq_sum, mul_one]
  linarith

end GibbsVariational

-- ============================================================================
-- ¬ß4. Shannon Entropy and Maximum Entropy
-- ============================================================================

section Entropy

variable {Œπ : Type*} [Fintype Œπ] [Nonempty Œπ]

/-- Shannon entropy: H(p) = -Œ£·µ¢ p·µ¢ log p·µ¢. -/
noncomputable def shannonEntropy (p : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  -‚àë i : Œπ, if p i = 0 then 0 else p i * log (p i)

omit [Nonempty Œπ] in
/-- Entropy is non-negative for probability distributions. -/
theorem shannonEntropy_nonneg (p : Œπ ‚Üí ‚Ñù)
    (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hp_sum : ‚àë i : Œπ, p i = 1) :
    0 ‚â§ shannonEntropy p := by
  simp only [shannonEntropy]
  rw [neg_nonneg]
  apply Finset.sum_nonpos
  intro i _
  by_cases hi : p i = 0
  ¬∑ simp [hi]
  ¬∑ simp only [hi, ‚ÜìreduceIte]
    have hp_pos : 0 < p i := (hp_nonneg i).lt_of_ne' hi
    have hp_le : p i ‚â§ 1 := by
      calc p i ‚â§ ‚àë j : Œπ, p j := Finset.single_le_sum (Œª j _ => hp_nonneg j) (Finset.mem_univ i)
        _ = 1 := hp_sum
    have hlog : log (p i) ‚â§ 0 := log_nonpos (le_of_lt hp_pos) hp_le
    exact mul_nonpos_of_nonneg_of_nonpos (le_of_lt hp_pos) hlog

/-- Maximum entropy is achieved by uniform distribution.

Proof: KL(p ‚Äñ uniform) ‚â• 0, and KL(p ‚Äñ uniform) = log n - H(p). -/
theorem shannonEntropy_le_log_card (p : Œπ ‚Üí ‚Ñù)
    (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hp_sum : ‚àë i : Œπ, p i = 1) :
    shannonEntropy p ‚â§ log (Fintype.card Œπ) := by
  -- Use KL(p ‚Äñ uniform) ‚â• 0
  set n := (Fintype.card Œπ : ‚Ñù) with hn_def
  have hn_pos : 0 < n := Nat.cast_pos.mpr Fintype.card_pos
  have hn_ne : n ‚â† 0 := ne_of_gt hn_pos
  set q : Œπ ‚Üí ‚Ñù := Œª _ => 1 / n with hq_def
  have hq_pos : ‚àÄ i, 0 < q i := fun _ => by simp [hq_def]; positivity
  have hq_sum : ‚àë i, q i = 1 := by
    simp only [hq_def, Finset.sum_const, Finset.card_univ, nsmul_eq_mul, hn_def]
    field_simp
  have hkl := kl_nonneg' hp_nonneg hq_pos hp_sum hq_sum
  -- KL(p ‚Äñ q) = -H(p) - Œ£ p·µ¢ log(1/n) = -H(p) + log n
  suffices h : klFinite p q = -shannonEntropy p + log n by linarith
  simp only [klFinite, shannonEntropy]
  -- Each term: if p=0 then 0 else p*log(p/q) = (if p=0 then 0 else p*log p) + p*log n
  have hterm : ‚àÄ i, (if p i = 0 then (0 : ‚Ñù) else p i * log (p i / q i)) =
      (if p i = 0 then (0 : ‚Ñù) else p i * log (p i)) + p i * log n := by
    intro i
    by_cases hp0 : p i = 0
    ¬∑ simp [hp0]
    ¬∑ simp only [hp0, ‚ÜìreduceIte]
      have hq_ne : q i ‚â† 0 := ne_of_gt (hq_pos i)
      rw [log_div hp0 hq_ne]
      have : log (q i) = -log n := by
        simp only [hq_def, log_div one_ne_zero hn_ne, log_one, zero_sub]
      rw [this]; ring
  simp_rw [hterm]
  rw [Finset.sum_add_distrib, ‚Üê Finset.sum_mul, hp_sum, one_mul, neg_neg]

/-- Entropy of uniform distribution. -/
theorem shannonEntropy_uniform :
    shannonEntropy (Œª _ : Œπ => 1 / Fintype.card Œπ) = log (Fintype.card Œπ) := by
  simp only [shannonEntropy]
  have hcard : (0 : ‚Ñù) < Fintype.card Œπ := Nat.cast_pos.mpr Fintype.card_pos
  have hne : (Fintype.card Œπ : ‚Ñù) ‚â† 0 := ne_of_gt hcard
  have hunif_pos : (0 : ‚Ñù) < 1 / Fintype.card Œπ := by positivity
  have hunif_ne : (1 : ‚Ñù) / Fintype.card Œπ ‚â† 0 := ne_of_gt hunif_pos
  simp only [hunif_ne, ‚ÜìreduceIte, log_div one_ne_zero hne, log_one, zero_sub]
  rw [Finset.sum_const, Finset.card_univ, nsmul_eq_mul]
  field_simp

/-- Entropy of softmax: H(softmax(s, Œ±)) = log Z - Œ± ¬∑ ùîº[s]. -/
theorem shannonEntropy_softmax (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    shannonEntropy (softmax s Œ±) =
    log (partitionFn s Œ±) - Œ± * ‚àë i : Œπ, softmax s Œ± i * s i := by
  simp only [shannonEntropy, softmax, partitionFn]
  have hZ : 0 < ‚àë j : Œπ, exp (Œ± * s j) := partitionFn_pos s Œ±
  have hne : (‚àë j : Œπ, exp (Œ± * s j)) ‚â† 0 := ne_of_gt hZ
  have hsm_pos : ‚àÄ i, exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j) ‚â† 0 := by
    intro i; exact ne_of_gt (div_pos (exp_pos _) hZ)
  simp only [hsm_pos, ‚ÜìreduceIte]
  have hlog : ‚àÄ i, log (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) =
                   Œ± * s i - log (‚àë j : Œπ, exp (Œ± * s j)) := by
    intro i; rw [log_div (ne_of_gt (exp_pos _)) hne, log_exp]
  simp_rw [hlog]
  have hsum1 : ‚àë i : Œπ, exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j) = 1 := by
    rw [‚Üê Finset.sum_div, div_self hne]
  calc -‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * (Œ± * s i - log (‚àë j : Œπ, exp (Œ± * s j)))
      = -‚àë i : Œπ, ((exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * (Œ± * s i) -
                   (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * log (‚àë j : Œπ, exp (Œ± * s j))) := by
        congr 1; apply Finset.sum_congr rfl; intros; ring
    _ = -(‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * (Œ± * s i) -
          ‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * log (‚àë j : Œπ, exp (Œ± * s j))) := by
        rw [Finset.sum_sub_distrib]
    _ = -(‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * (Œ± * s i) -
          (‚àë i : Œπ, exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * log (‚àë j : Œπ, exp (Œ± * s j))) := by
        rw [‚Üê Finset.sum_mul]
    _ = -(‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * (Œ± * s i) - 1 * log (‚àë j : Œπ, exp (Œ± * s j))) := by
        rw [hsum1]
    _ = log (‚àë j : Œπ, exp (Œ± * s j)) - ‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * (Œ± * s i) := by ring
    _ = log (‚àë j : Œπ, exp (Œ± * s j)) - ‚àë i : Œπ, Œ± * ((exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * s i) := by
        congr 1; apply Finset.sum_congr rfl; intros; ring
    _ = log (‚àë j : Œπ, exp (Œ± * s j)) - Œ± * ‚àë i : Œπ, (exp (Œ± * s i) / ‚àë j : Œπ, exp (Œ± * s j)) * s i := by
        rw [‚Üê Finset.mul_sum]

/-- Entropy-regularized objective: G_Œ±(p, s) = ‚ü®s, p‚ü© + (1/Œ±) H(p). -/
noncomputable def entropyRegObjective (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (p : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë i : Œπ, p i * s i + (1 / Œ±) * shannonEntropy p

/-- The maximum value of the entropy-regularized objective. -/
theorem entropyRegObjective_softmax (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (hŒ± : 0 < Œ±) :
    entropyRegObjective s Œ± (softmax s Œ±) = (1 / Œ±) * log (partitionFn s Œ±) := by
  simp only [entropyRegObjective, shannonEntropy_softmax]
  have hne : Œ± ‚â† 0 := ne_of_gt hŒ±
  field_simp
  ring

omit [Nonempty Œπ] in
/-- Shannon entropy equals sum of negMulLog for distributions. -/
private theorem shannonEntropy_eq_negMulLog (p : Œπ ‚Üí ‚Ñù)
    (_hp_nonneg : ‚àÄ i, 0 ‚â§ p i) :
    shannonEntropy p = ‚àë i, Real.negMulLog (p i) := by
  simp only [shannonEntropy, Real.negMulLog]
  rw [‚Üê Finset.sum_neg_distrib]
  apply Finset.sum_congr rfl
  intro i _
  by_cases hp0 : p i = 0
  ¬∑ simp [hp0]
  ¬∑ simp only [hp0, ‚ÜìreduceIte, neg_mul]

/-- Fact 5: Softmax maximizes the entropy-regularized objective.

Proof: `gibbs_variational` gives `H(p) + Œ±‚ü®p,s‚ü© ‚â§ H(q) + Œ±‚ü®q,s‚ü©`;
dividing by `Œ± > 0` yields the result. -/
theorem softmax_maximizes_entropyReg (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (hŒ± : 0 < Œ±)
    (p : Œπ ‚Üí ‚Ñù) (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hp_sum : ‚àë i : Œπ, p i = 1) :
    entropyRegObjective s Œ± p ‚â§ entropyRegObjective s Œ± (softmax s Œ±) := by
  simp only [entropyRegObjective]
  have hgibbs := gibbs_variational s Œ± p hp_nonneg hp_sum
  -- Rewrite Shannon entropy as sum of negMulLog
  rw [shannonEntropy_eq_negMulLog p hp_nonneg,
      shannonEntropy_eq_negMulLog (softmax s Œ±) (fun i => softmax_nonneg s Œ± i)]
  -- gibbs_variational: Œ£ negMulLog(p·µ¢) + Œ± Œ£ p·µ¢s·µ¢ ‚â§ Œ£ negMulLog(q·µ¢) + Œ± Œ£ q·µ¢s·µ¢
  -- We need: Œ£ p·µ¢s·µ¢ + (1/Œ±)(Œ£ negMulLog(p·µ¢)) ‚â§ Œ£ q·µ¢s·µ¢ + (1/Œ±)(Œ£ negMulLog(q·µ¢))
  -- This follows from dividing by Œ± > 0
  have hŒ±_ne : Œ± ‚â† 0 := ne_of_gt hŒ±
  -- gibbs_variational: H(p)+Œ±‚ü®p,s‚ü© ‚â§ H(q)+Œ±‚ü®q,s‚ü©, divide by Œ± > 0
  have h := div_le_div_of_nonneg_right hgibbs (le_of_lt hŒ±)
  simp only [add_div, mul_div_cancel_left‚ÇÄ _ hŒ±_ne] at h
  -- h : Œ£ negMulLog(p·µ¢) / Œ± + Œ£ p·µ¢s·µ¢ ‚â§ Œ£ negMulLog(q·µ¢) / Œ± + Œ£ q·µ¢s·µ¢
  -- Convert div to 1/Œ± * to match entropyRegObjective
  simp only [div_eq_inv_mul] at h
  rw [show (Œ±‚Åª¬π : ‚Ñù) = 1 / Œ± from by ring] at h
  linarith

omit [Nonempty Œπ] in
/-- KL divergence zero implies distributions are equal (when q > 0 and sums match). -/
private theorem kl_eq_zero_imp_eq (p q : Œπ ‚Üí ‚Ñù) (hq_pos : ‚àÄ i, 0 < q i)
    (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hsum : ‚àë i, p i = ‚àë i, q i)
    (hkl : klFinite p q = 0) :
    p = q := by
  rw [kl_eq_sum_klFun p q hq_pos hp_nonneg hsum] at hkl
  funext i
  have hpi_div_qi_nonneg : 0 ‚â§ p i / q i := div_nonneg (hp_nonneg i) (le_of_lt (hq_pos i))
  have hqi_pos : 0 < q i := hq_pos i
  have hqi_nonneg : 0 ‚â§ q i := le_of_lt hqi_pos
  -- Each term q_i * klFun(p_i/q_i) ‚â• 0 and their sum = 0
  have hterm_nonneg : ‚àÄ j, 0 ‚â§ q j * InformationTheory.klFun (p j / q j) := by
    intro j; exact mul_nonneg (le_of_lt (hq_pos j))
      (InformationTheory.klFun_nonneg (div_nonneg (hp_nonneg j) (le_of_lt (hq_pos j))))
  have hterm_zero : q i * InformationTheory.klFun (p i / q i) = 0 := by
    have hsz := Finset.sum_eq_zero_iff_of_nonneg (fun j _ => hterm_nonneg j) |>.mp hkl
    exact hsz i (Finset.mem_univ i)
  -- q_i > 0 so klFun(p_i/q_i) = 0, hence p_i/q_i = 1
  rcases mul_eq_zero.mp hterm_zero with hq0 | hkl0
  ¬∑ exact absurd hq0 (ne_of_gt hqi_pos)
  ¬∑ rw [InformationTheory.klFun_eq_zero_iff hpi_div_qi_nonneg] at hkl0
    exact div_eq_one_iff_eq (ne_of_gt hqi_pos) |>.mp hkl0

/-- Softmax is the unique maximizer.

Proof: equality in the objective ‚üπ KL(p ‚Äñ softmax) = 0 (via `speakerObj_plus_kl`),
hence p = softmax (via `kl_eq_zero_imp_eq`). -/
theorem softmax_unique_maximizer (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (hŒ± : 0 < Œ±)
    (p : Œπ ‚Üí ‚Ñù) (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hp_sum : ‚àë i : Œπ, p i = 1)
    (h_max : entropyRegObjective s Œ± p = entropyRegObjective s Œ± (softmax s Œ±)) :
    p = softmax s Œ± := by
  set q := softmax s Œ± with hq_def
  have hq_pos : ‚àÄ i, 0 < q i := fun i => softmax_pos s Œ± i
  have hq_sum : ‚àë i, q i = 1 := softmax_sum_eq_one s Œ±
  -- From speakerObj_plus_kl: speakerObj(p) + KL(p ‚Äñ q) = logSumExp = speakerObj(q) + 0
  have h_p := speakerObj_plus_kl s Œ± p hp_nonneg hp_sum
  have h_q := speakerObj_plus_kl s Œ± q (fun i => le_of_lt (hq_pos i)) hq_sum
  -- KL(q ‚Äñ q) = 0
  have hkl_self : klFinite q q = 0 := by
    simp only [klFinite]
    apply Finset.sum_eq_zero
    intro i _
    have hne : q i ‚â† 0 := ne_of_gt (hq_pos i)
    simp [hne]
  rw [hkl_self, add_zero] at h_q
  -- So KL(p ‚Äñ q) = logSumExp - speakerObj(p) = speakerObj(q) - speakerObj(p)
  have hkl_val : klFinite p q = speakerObj s Œ± q - speakerObj s Œ± p := by linarith
  -- entropyRegObjective equality means speakerObj equality (up to rescaling)
  -- entropyRegObjective = Œ£ p*s + (1/Œ±) * H(p)
  -- speakerObj = Œ£ negMulLog(p) + Œ± * Œ£ p*s  (i.e. H(p) + Œ±‚ü®p,s‚ü© but per-element)
  -- We showed: entropyRegObj(p) = (1/Œ±) * speakerObj(p)
  have hobj_eq : speakerObj s Œ± p = speakerObj s Œ± q := by
    -- entropyRegObjective = Œ£ p*s + (1/Œ±)*H(p) = (1/Œ±)(H(p) + Œ± Œ£ p*s) = (1/Œ±)*speakerObj
    have hŒ±_ne' : Œ± ‚â† 0 := ne_of_gt hŒ±
    have hconv : ‚àÄ r : Œπ ‚Üí ‚Ñù, (‚àÄ i, 0 ‚â§ r i) ‚Üí
        entropyRegObjective s Œ± r = (1 / Œ±) * speakerObj s Œ± r := by
      intro r hr_nn
      simp only [entropyRegObjective, speakerObj]
      rw [shannonEntropy_eq_negMulLog r hr_nn, Finset.mul_sum, ‚Üê Finset.sum_add_distrib,
          Finset.mul_sum]
      apply Finset.sum_congr rfl
      intro i _
      field_simp
      ring
    have h1 := hconv p hp_nonneg
    have h2 := hconv q (fun i => le_of_lt (hq_pos i))
    have hŒ±_ne : (1 : ‚Ñù) / Œ± ‚â† 0 := by positivity
    rw [h1, h2] at h_max
    exact mul_left_cancel‚ÇÄ hŒ±_ne h_max
  -- Therefore KL(p ‚Äñ q) = 0
  have hkl_zero : klFinite p q = 0 := by linarith
  exact kl_eq_zero_imp_eq p q hq_pos hp_nonneg (by rw [hp_sum, hq_sum]) hkl_zero

/-- Free energy (from statistical mechanics). -/
noncomputable def freeEnergy (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (p : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  -‚àë i : Œπ, p i * s i - (1 / Œ±) * shannonEntropy p

/-- Softmax is the Boltzmann distribution: minimizes free energy. -/
theorem softmax_minimizes_freeEnergy (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) (hŒ± : 0 < Œ±)
    (p : Œπ ‚Üí ‚Ñù) (hp_nonneg : ‚àÄ i, 0 ‚â§ p i) (hp_sum : ‚àë i : Œπ, p i = 1) :
    freeEnergy s Œ± (softmax s Œ±) ‚â§ freeEnergy s Œ± p := by
  simp only [freeEnergy]
  have h := softmax_maximizes_entropyReg s Œ± hŒ± p hp_nonneg hp_sum
  simp only [entropyRegObjective] at h
  linarith

/-- The log-partition function is convex in Œ±.

TODO: Proof sketch ‚Äî second derivative is variance of s under softmax(s, Œ±),
which is ‚â• 0. Requires H√∂lder's inequality or the second-derivative test
for finite sums, which is not currently available in Mathlib in usable form. -/
theorem logSumExp_convex (s : Œπ ‚Üí ‚Ñù) :
    ConvexOn ‚Ñù Set.univ (Œª Œ± => logSumExp s Œ±) := by
  sorry

/-- Derivative of log-partition gives expected value.

TODO: Proof sketch ‚Äî `d/dŒ± log(Œ£ exp(Œ± s·µ¢)) = Œ£ s·µ¢ exp(Œ± s·µ¢) / Œ£ exp(Œ± s‚±º)`.
Requires `HasDerivAt` for `log ‚àò Œ£ exp(Œ± ¬∑ s·µ¢)` via chain rule and `hasDerivAt_exp`,
then `hasDerivAt_finset_sum`. Doable but involved; lower priority. -/
theorem deriv_logSumExp (s : Œπ ‚Üí ‚Ñù) (Œ± : ‚Ñù) :
    deriv (Œª Œ± => logSumExp s Œ±) Œ± = ‚àë i : Œπ, softmax s Œ± i * s i := by
  sorry

/-- Strong duality: max entropy = min free energy. -/
theorem max_entropy_duality (s : Œπ ‚Üí ‚Ñù) (c : ‚Ñù)
    (Œ± : ‚Ñù) (_hŒ± : 0 < Œ±) (h_constraint : ‚àë i : Œπ, softmax s Œ± i * s i = c) :
    shannonEntropy (softmax s Œ±) = log (partitionFn s Œ±) - Œ± * c := by
  rw [shannonEntropy_softmax, h_constraint]

end Entropy

-- ============================================================================
-- ¬ß5. Bayesian Optimality
-- ============================================================================

section BayesianOptimality

variable {Œπ : Type*} [Fintype Œπ]

/-- **Bayesian optimality**: The normalized posterior maximizes weighted log-likelihood
on the probability simplex.

For weights w·µ¢ ‚â• 0 with C = Œ£w·µ¢ > 0, and any distribution L on the simplex
(L·µ¢ > 0, Œ£ L·µ¢ = 1), the normalized posterior p*·µ¢ = w·µ¢/C satisfies:

  Œ£·µ¢ w·µ¢ ¬∑ log(L·µ¢) ‚â§ Œ£·µ¢ w·µ¢ ¬∑ log(p*·µ¢)

This is used for listener optimality: with w·µ¢ = P(m)¬∑S(u|m), the
Bayesian listener L*(m|u) = w·µ¢/C maximizes Œ£_m P(m)¬∑S(u|m)¬∑log L(m|u). -/
theorem bayesian_maximizes (w : Œπ ‚Üí ‚Ñù) (hw_nonneg : ‚àÄ i, 0 ‚â§ w i)
    (hC_pos : 0 < ‚àë i, w i)
    (L : Œπ ‚Üí ‚Ñù) (hL_pos : ‚àÄ i, 0 < L i) (hL_sum : ‚àë i, L i = 1) :
    ‚àë i, w i * log (L i) ‚â§ ‚àë i, w i * log (w i / ‚àë j, w j) := by
  set C := ‚àë i, w i with hC_def
  have hC_ne : C ‚â† 0 := ne_of_gt hC_pos
  have hp_nonneg : ‚àÄ i, 0 ‚â§ w i / C := Œª i => div_nonneg (hw_nonneg i) (le_of_lt hC_pos)
  have hp_sum : ‚àë i, w i / C = 1 := by rw [‚Üê Finset.sum_div, div_self hC_ne]
  have hkl : 0 ‚â§ klFinite (Œª i => w i / C) L :=
    kl_nonneg _ L hL_pos hp_nonneg (by rw [hp_sum, hL_sum])
  suffices h : (‚àë i, w i * log (w i / C)) - (‚àë i, w i * log (L i)) =
      C * klFinite (fun i => w i / C) L by
    linarith [mul_nonneg (le_of_lt hC_pos) hkl]
  unfold klFinite
  rw [Finset.mul_sum, ‚Üê Finset.sum_sub_distrib]
  apply Finset.sum_congr rfl
  intro i _
  by_cases hwi : w i = 0
  ¬∑ simp [hwi]
  ¬∑ have hwC_ne : w i / C ‚â† 0 := div_ne_zero hwi hC_ne
    simp only [hwC_ne, ‚ÜìreduceIte]
    have hwi_pos : 0 < w i := lt_of_le_of_ne (hw_nonneg i) (Ne.symm hwi)
    rw [show C * (w i / C * log (w i / C / L i)) = w i * log (w i / C / L i) from by
      rw [‚Üê mul_assoc]; congr 1; field_simp]
    rw [log_div (ne_of_gt (div_pos hwi_pos hC_pos)) (ne_of_gt (hL_pos i))]
    ring

end BayesianOptimality

end Core
