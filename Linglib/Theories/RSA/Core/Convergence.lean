/-
# RSA Convergence Theory

Proves that RSA dynamics converge by showing G_Œ± is monotonically increasing.

## Results

1. Concavity: G_Œ± is concave in S (fixed L) and concave in L (fixed S)
2. Alternating maximization: RSA speaker/listener updates maximize G_Œ±
3. Monotonicity: G_Œ±(S_t, L_t) ‚â§ G_Œ±(S_{t+1}, L_{t+1}) for all t
4. Convergence: RSA dynamics converge to a fixed point

These results guarantee that RSA predictions are well-defined: the iterative
reasoning process converges rather than oscillating or diverging.

## References

- Zaslavsky, N., Hu, J., & Levy, R. (2020). A Rate-Distortion view of human
  pragmatic reasoning. Proposition 1.
- Csisz√°r, I. & Tusn√°dy, G. (1984). Information geometry and alternating
  minimization procedures.
-/

import Mathlib.Analysis.SpecialFunctions.Log.Basic
import Mathlib.Analysis.SpecialFunctions.Log.NegMulLog
import Mathlib.Analysis.Convex.SpecificFunctions.Basic
import Mathlib.Analysis.Convex.Function
import Mathlib.Topology.Order.Basic
import Mathlib.Data.Real.Basic
import Mathlib.Algebra.BigOperators.Field
import Linglib.Theories.RSA.Core.Softmax.Basic

namespace RSA.Convergence

open Real Classical


/--
RSA scenario with real-valued Œ± for convergence proofs.

This is the mathematical version used for proving convergence.
For computation, use `RSAScenario` from Core.lean.
-/
structure RSAScenarioR where
  /-- Finite type of meanings/worlds -/
  M : Type*
  /-- Finite type of utterances -/
  U : Type*
  /-- Fintype instances -/
  [finM : Fintype M]
  [finU : Fintype U]
  /-- Prior over meanings -/
  prior : M ‚Üí ‚Ñù
  prior_nonneg : ‚àÄ m, 0 ‚â§ prior m
  prior_pos : ‚àÉ m, 0 < prior m
  /-- Lexicon: applicability of utterance to meaning -/
  lexicon : U ‚Üí M ‚Üí ‚Ñù
  lexicon_nonneg : ‚àÄ u m, 0 ‚â§ lexicon u m
  /-- Rationality parameter -/
  Œ± : ‚Ñù
  Œ±_nonneg : 0 ‚â§ Œ±

attribute [instance] RSAScenarioR.finM RSAScenarioR.finU


/-- Normalization constant (partition function). -/
noncomputable def Z {Œ± : Type*} [Fintype Œ±] (f : Œ± ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë a, f a

/-- Normalized distribution. -/
noncomputable def normalize {Œ± : Type*} [Fintype Œ±] (f : Œ± ‚Üí ‚Ñù) (a : Œ±) : ‚Ñù :=
  if Z f = 0 then 0 else f a / Z f

/-- Shannon entropy H(X) = -Œ£ p(x) log p(x). -/
noncomputable def entropy {Œ± : Type*} [Fintype Œ±] (p : Œ± ‚Üí ‚Ñù) : ‚Ñù :=
  -‚àë a, if p a = 0 then 0 else p a * log (p a)

/-- Literal listener: L‚ÇÄ(m|u) ‚àù lexicon(u,m) ¬∑ prior(m) -/
noncomputable def L0 (S : RSAScenarioR) (u : S.U) (m : S.M) : ‚Ñù :=
  S.lexicon u m * S.prior m

/-- Speaker utility: V_L(m,u) = log L(m|u) -/
noncomputable def utility {S : RSAScenarioR} (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (m : S.M) (u : S.U) : ‚Ñù :=
  if L u m ‚â§ 0 then 0 else log (L u m)

/-- Pragmatic speaker: S(u|m) ‚àù L(m|u)^Œ± -/
noncomputable def speakerScore (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (m : S.M) (u : S.U) : ‚Ñù :=
  if L u m ‚â§ 0 then 0 else (L u m).rpow S.Œ±

-- Softmax-based speaker (inherits all softmax properties)

/-- Pragmatic speaker as softmax (normalized distribution).

  S(u|m) = softmax(utility(¬∑, m), Œ±)(u)

By defining RSA speaker via softmax, all softmax properties
(sum to 1, positivity, odds, limits) transfer directly.

The `utility` function is defined above as `log L(m|u)` when `L > 0`.
For full RSA with cost, use `utility - cost` as the score function.
-/
noncomputable def speakerSoftmax (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (m : S.M) : S.U ‚Üí ‚Ñù :=
  Softmax.softmax (Œª u => utility L m u) S.Œ±

/-- Speaker softmax sums to 1 (valid probability distribution). -/
theorem speakerSoftmax_sum_one (S : RSAScenarioR) [Nonempty S.U] (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (m : S.M) :
    ‚àë u, speakerSoftmax S L m u = 1 :=
  Softmax.softmax_sum_eq_one _ S.Œ±

/-- Speaker softmax is positive. -/
theorem speakerSoftmax_pos (S : RSAScenarioR) [Nonempty S.U] (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (m : S.M) (u : S.U) :
    0 < speakerSoftmax S L m u :=
  Softmax.softmax_pos _ S.Œ± u

/-- Speaker softmax probability ratio from utility differences.

  S(u‚ÇÅ|m) / S(u‚ÇÇ|m) = exp(Œ± ¬∑ (utility(u‚ÇÅ, m) - utility(u‚ÇÇ, m)))

This is Fact 2 from Franke & Degen: odds determined by score differences.
-/
theorem speakerSoftmax_odds (S : RSAScenarioR) [Nonempty S.U] (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (m : S.M) (u‚ÇÅ u‚ÇÇ : S.U) :
    speakerSoftmax S L m u‚ÇÅ / speakerSoftmax S L m u‚ÇÇ =
    Real.exp (S.Œ± * (utility L m u‚ÇÅ - utility L m u‚ÇÇ)) :=
  Softmax.softmax_odds _ S.Œ± u‚ÇÅ u‚ÇÇ

/-- At Œ± = 0, speaker is uniform (ignores utility entirely). -/
theorem speakerSoftmax_zero (S : RSAScenarioR) [Nonempty S.U] (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (m : S.M)
    (hŒ± : S.Œ± = 0) :
    speakerSoftmax S L m = Œª _ => 1 / (Fintype.card S.U : ‚Ñù) := by
  simp only [speakerSoftmax, hŒ±]
  exact Softmax.softmax_zero _

/-- Higher utility ‚Üí higher speaker probability (for Œ± > 0). -/
theorem speakerSoftmax_mono (S : RSAScenarioR) [Nonempty S.U] (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (hŒ± : 0 < S.Œ±) (m : S.M) (u‚ÇÅ u‚ÇÇ : S.U)
    (h : utility L m u‚ÇÅ ‚â§ utility L m u‚ÇÇ) :
    speakerSoftmax S L m u‚ÇÅ ‚â§ speakerSoftmax S L m u‚ÇÇ :=
  Softmax.softmax_mono _ hŒ± u‚ÇÅ u‚ÇÇ h

/-- Pragmatic listener: L(m|u) ‚àù P(m) ¬∑ S(u|m) -/
noncomputable def listenerScore (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (u : S.U) (m : S.M) : ‚Ñù :=
  S.prior m * Spk m u


/-!
## The RSA Objective Function G_Œ±

RSA dynamics implicitly optimize an objective function G_Œ± (Zaslavsky et al. 2020):

  G_Œ±(S, L) = H_S(U|M) + Œ± ¬∑ E_S[V_L]

where:
- H_S(U|M) = Speaker's conditional entropy = Œ£‚Çò P(m) ¬∑ H(S(¬∑|m)).
  This measures the "cost" of the speaker's lexicon. Lower entropy means more
  deterministic (easier to produce) utterances.

- E_S[V_L] = Expected listener utility = Œ£‚Çò,·µ§ P(m) S(u|m) log L(m|u).
  This measures how well the listener can recover the intended meaning.

- Œ± = Rationality parameter controlling the cost/informativity tradeoff.
  - Œ± = 0: Maximum entropy (speaker ignores listener)
  - Œ± = 1: Rate-distortion optimum (information-theoretic balance)
  - Œ± ‚Üí ‚àû: NeoGricean limit (maximum informativity)

## Why RSA Converges

G_Œ± is concave in both S (for fixed L) and L (for fixed S). Since RSA
alternately maximizes over S and L, this is an instance of alternating
maximization which converges to a fixed point.

G_Œ± balances two pressures:
1. Compression (H_S): Keep utterances simple/predictable
2. Communication (E_S[V_L]): Help the listener understand

The rationality parameter Œ± controls which pressure dominates.
-/

/-- Speaker's conditional entropy H_S(U|M).

This measures the "cost" of the speaker's utterance distribution.
Lower entropy = more predictable (less costly) choices. -/
noncomputable def H_S (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë m, S.prior m * entropy (Œª u => normalize (Spk m) u)

/-- Expected listener utility E_S[V_L].

This measures how well the listener recovers the speaker's intended meaning.
Higher utility = better communication. -/
noncomputable def E_VL (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (L : S.U ‚Üí S.M ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë m, ‚àë u, S.prior m * normalize (Spk m) u * utility L m u

/--
**The RSA Objective**: G_Œ±(S,L) = H_S(U|M) + Œ± ¬∑ E_S[V_L]

This is the function that RSA dynamics maximize. RSA convergence follows from:
1. G_Œ± is concave in S (for fixed L)
2. G_Œ± is concave in L (for fixed S)
3. G_Œ± is bounded above (by log |U|)
4. RSA alternately maximizes over S and L

Therefore G_Œ± is monotonically non-decreasing and bounded, so it converges.
-/
noncomputable def G_Œ± (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (L : S.U ‚Üí S.M ‚Üí ‚Ñù) : ‚Ñù :=
  H_S S Spk + S.Œ± * E_VL S Spk L


/-- One step of RSA dynamics: given listener L, compute optimal speaker. -/
noncomputable def speakerUpdate (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (m : S.M) (u : S.U) : ‚Ñù :=
  speakerScore S L m u

/-- One step of RSA dynamics: given speaker S, compute optimal listener. -/
noncomputable def listenerUpdate (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (u : S.U) (m : S.M) : ‚Ñù :=
  listenerScore S Spk u m

/-- RSA state: a speaker-listener pair. -/
structure RSAState (S : RSAScenarioR) where
  speaker : S.M ‚Üí S.U ‚Üí ‚Ñù
  listener : S.U ‚Üí S.M ‚Üí ‚Ñù

/-- Initialize RSA from literal listener. -/
noncomputable def initRSA (S : RSAScenarioR) : RSAState S where
  speaker := Œª m u => speakerScore S (L0 S) m u
  listener := Œª u m => L0 S u m

/-- One full step of RSA dynamics. -/
noncomputable def stepRSA (S : RSAScenarioR) (state : RSAState S) : RSAState S where
  speaker := speakerUpdate S state.listener
  listener := listenerUpdate S (speakerUpdate S state.listener)

/-- RSA dynamics after n iterations. -/
noncomputable def iterateRSA (S : RSAScenarioR) (n : ‚Ñï) : RSAState S :=
  (stepRSA S)^[n] (initRSA S)


/-!
## G_Œ± Concavity

The function `negMulLog x = -x * log x` is concave on [0, ‚àû) (Mathlib: `concaveOn_negMulLog`).
Since entropy H(p) = Œ£·µ¢ negMulLog(p·µ¢), entropy is concave in p.

Therefore:
- G_Œ±[S, L] = H_S(U|M) + Œ±¬∑E_S[V_L]
- H_S(U|M) = Œ£‚Çò P(m) ¬∑ H(S(¬∑|m)) is concave in S (sum of concave)
- E_S[V_L] is linear in S
- G_Œ± is concave in S (for fixed L)

Similarly, log is concave, so G_Œ± is concave in L (for fixed S).
-/

/-- negMulLog is concave on [0, ‚àû). -/
theorem negMulLog_concave : ConcaveOn ‚Ñù (Set.Ici (0 : ‚Ñù)) Real.negMulLog :=
  Real.concaveOn_negMulLog

/-- Log is concave on (0, ‚àû). -/
theorem log_concave : ConcaveOn ‚Ñù (Set.Ioi (0 : ‚Ñù)) Real.log :=
  strictConcaveOn_log_Ioi.concaveOn

/-- Projection is a linear map: p ‚Ü¶ p(i) is linear. -/
def projLinearMap {Œ± : Type*} (i : Œ±) : (Œ± ‚Üí ‚Ñù) ‚Üí‚Çó[‚Ñù] ‚Ñù where
  toFun p := p i
  map_add' _ _ := rfl
  map_smul' _ _ := rfl

/-- negMulLog composed with projection is concave. -/
theorem negMulLog_proj_concave {Œ± : Type*} (i : Œ±) :
    ConcaveOn ‚Ñù {p : Œ± ‚Üí ‚Ñù | 0 ‚â§ p i} (Œª p => Real.negMulLog (p i)) := by
  have h1 : ConcaveOn ‚Ñù (Set.Ici (0 : ‚Ñù)) Real.negMulLog := Real.concaveOn_negMulLog
  have h2 := h1.comp_linearMap (projLinearMap i)
  have hset : {p : Œ± ‚Üí ‚Ñù | 0 ‚â§ p i} = projLinearMap i ‚Åª¬π' Set.Ici 0 := by
    ext p
    simp only [Set.mem_setOf_eq, Set.mem_preimage, Set.mem_Ici]
    rfl
  have hfun : (Œª p => Real.negMulLog (p i)) = Real.negMulLog ‚àò projLinearMap i := by
    ext p
    simp only [Function.comp_apply]
    rfl
  rw [hset, hfun]
  exact h2

/-- Helper: The constraint set {p | ‚àÄ i, 0 ‚â§ p i} is convex. -/
theorem convex_nonneg_functions {Œ± : Type*} :
    Convex ‚Ñù {p : Œ± ‚Üí ‚Ñù | ‚àÄ i, 0 ‚â§ p i} := by
  intro x hx y hy a b ha hb _hab
  simp only [Set.mem_setOf_eq] at hx hy ‚ä¢
  intro i
  simp only [Pi.add_apply, Pi.smul_apply, smul_eq_mul]
  have h1 : a * x i ‚â• 0 := mul_nonneg ha (hx i)
  have h2 : b * y i ‚â• 0 := mul_nonneg hb (hy i)
  linarith

/-- Helper: Finite sum of concave functions is concave (over a Finset). -/
theorem concaveOn_finset_sum' {Œ± : Type*} {E : Type*}
    [AddCommGroup E] [Module ‚Ñù E] {s : Set E} (hs : Convex ‚Ñù s)
    (f : Œ± ‚Üí E ‚Üí ‚Ñù) (F : Finset Œ±) (hf : ‚àÄ i ‚àà F, ConcaveOn ‚Ñù s (f i)) :
    ConcaveOn ‚Ñù s (Œª x => ‚àë i ‚àà F, f i x) := by
  classical
  induction F using Finset.induction_on with
  | empty =>
    simp only [Finset.sum_empty]
    exact concaveOn_const 0 hs
  | @insert a F' ha ih =>
    simp only [Finset.sum_insert ha]
    have hfa : ConcaveOn ‚Ñù s (f a) := hf a (Finset.mem_insert_self a F')
    have hrest : ConcaveOn ‚Ñù s (Œª x => ‚àë i ‚àà F', f i x) :=
      ih (Œª i hi => hf i (Finset.mem_insert_of_mem hi))
    exact hfa.add hrest

/-- Helper: Finite sum of concave functions is concave (over a Fintype). -/
theorem concaveOn_finset_sum {Œ± : Type*} [Fintype Œ±] {E : Type*}
    [AddCommGroup E] [Module ‚Ñù E] {s : Set E} (hs : Convex ‚Ñù s)
    (f : Œ± ‚Üí E ‚Üí ‚Ñù) (hf : ‚àÄ i, ConcaveOn ‚Ñù s (f i)) :
    ConcaveOn ‚Ñù s (Œª x => ‚àë i, f i x) := by
  apply concaveOn_finset_sum' hs f Finset.univ
  intro i _
  exact hf i

/-- Entropy is concave: H(p) = Œ£·µ¢ negMulLog(p·µ¢) is concave in p. -/
theorem entropy_concave_on_simplex {Œ± : Type*} [Fintype Œ±] :
    ConcaveOn ‚Ñù {p : Œ± ‚Üí ‚Ñù | ‚àÄ i, 0 ‚â§ p i}
      (Œª p => ‚àë i, Real.negMulLog (p i)) := by
  apply concaveOn_finset_sum convex_nonneg_functions
  intro i
  apply ConcaveOn.subset (negMulLog_proj_concave i)
  ¬∑ intro p hp
    simp only [Set.mem_setOf_eq] at hp ‚ä¢
    exact hp i
  ¬∑ exact convex_nonneg_functions

/-- Weighted sum of concave functions is concave. -/
theorem weighted_sum_concave {Œ± : Type*} [Fintype Œ±] {E : Type*}
    [AddCommGroup E] [Module ‚Ñù E] {s : Set E} (hs : Convex ‚Ñù s)
    (f : Œ± ‚Üí E ‚Üí ‚Ñù) (w : Œ± ‚Üí ‚Ñù) (hw : ‚àÄ i, 0 ‚â§ w i)
    (hf : ‚àÄ i, ConcaveOn ‚Ñù s (f i)) :
    ConcaveOn ‚Ñù s (Œª x => ‚àë i, w i * f i x) := by
  apply concaveOn_finset_sum hs
  intro i
  have h := (hf i).smul (hw i)
  have heq : (Œª x => w i * f i x) = w i ‚Ä¢ f i := by
    ext x
    simp only [Pi.smul_apply, smul_eq_mul]
  rw [heq]
  exact h


/--
Proposition 1, Part 1 (Zaslavsky et al.): G_Œ± is concave in S for fixed L.

On the probability simplex (where Œ£_u Spk m u = 1 and Spk m u ‚â• 0):
- normalize(Spk m) = Spk m (no normalization needed)
- H_S = Œ£_m P(m) ¬∑ entropy(Spk m) is weighted sum of entropies ‚Üí concave
- E_VL = Œ£_m,u P(m) ¬∑ Spk(m,u) ¬∑ V(L,m,u) is linear in Spk ‚Üí concave
- G_Œ± = H_S + Œ±¬∑E_VL is sum of concave functions ‚Üí concave
-/
theorem G_Œ±_concave_in_S (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù) :
    ConcaveOn ‚Ñù {Spk | (‚àÄ m u, 0 ‚â§ Spk m u) ‚àß (‚àÄ m, ‚àë u, Spk m u = 1)}
      (Œª Spk => G_Œ± S Spk L) := by
  -- Define the simplex domain
  let D := {Spk : S.M ‚Üí S.U ‚Üí ‚Ñù | (‚àÄ m u, 0 ‚â§ Spk m u) ‚àß (‚àÄ m, ‚àë u, Spk m u = 1)}
  -- The simplex is convex
  have hD_convex : Convex ‚Ñù D := by
    intro x hx y hy a b ha hb hab
    constructor
    ¬∑ -- Non-negativity: a * x m u + b * y m u ‚â• 0
      intro m u
      simp only [Pi.add_apply, Pi.smul_apply, smul_eq_mul]
      exact add_nonneg (mul_nonneg ha (hx.1 m u)) (mul_nonneg hb (hy.1 m u))
    ¬∑ -- Sum to 1: Œ£_u (a * x m u + b * y m u) = 1
      intro m
      simp only [Pi.add_apply, Pi.smul_apply, smul_eq_mul]
      rw [Finset.sum_add_distrib]
      rw [‚Üê Finset.mul_sum, ‚Üê Finset.mul_sum]
      rw [hx.2 m, hy.2 m]
      linarith
  -- On the simplex, normalize(Spk m) = Spk m
  have hnorm_eq : ‚àÄ Spk ‚àà D, ‚àÄ m u, normalize (Spk m) u = Spk m u := by
    intro Spk hSpk m u
    unfold normalize Z
    have hsum : ‚àë v, Spk m v = 1 := hSpk.2 m
    have hne : ‚àë a, Spk m a ‚â† 0 := by rw [hsum]; exact one_ne_zero
    rw [if_neg hne, hsum, div_one]
  -- H_S on the simplex: H_S(Spk) = Œ£_m P(m) ¬∑ entropy(Spk m)
  -- This is a weighted sum of entropies, which is concave
  have hH_concave : ConcaveOn ‚Ñù D (Œª Spk => H_S S Spk) := by
    unfold H_S
    -- For each m, entropy(normalize(Spk m)) = entropy(Spk m) on simplex
    -- entropy(Spk m) is concave in Spk m
    -- Weighted sum with P(m) ‚â• 0 preserves concavity
    apply weighted_sum_concave hD_convex
    ¬∑ exact S.prior_nonneg
    ¬∑ intro m
      -- Need: Spk ‚Ü¶ entropy(normalize(Spk m)) is concave on D
      -- On D, this equals entropy(Spk m)
      -- First, show entropy equals ‚àë negMulLog on non-negative inputs
      have hentropy_eq : ‚àÄ p : S.U ‚Üí ‚Ñù, (‚àÄ u, 0 ‚â§ p u) ‚Üí
          entropy p = ‚àë u, Real.negMulLog (p u) := by
        intro p hp
        unfold entropy Real.negMulLog
        simp only [neg_mul]
        rw [‚Üê Finset.sum_neg_distrib]
        apply Finset.sum_congr rfl
        intro u _
        by_cases hpu : p u = 0
        ¬∑ simp only [hpu, Real.log_zero, mul_zero, neg_zero, ite_true]
        ¬∑ simp only [hpu, ‚ÜìreduceIte]
      -- entropy is concave (via entropy_concave_on_simplex)
      have hentropy_concave : ConcaveOn ‚Ñù {p : S.U ‚Üí ‚Ñù | ‚àÄ u, 0 ‚â§ p u}
          (Œª p => entropy p) := by
        apply ConcaveOn.congr entropy_concave_on_simplex
        intro p hp
        exact (hentropy_eq p hp).symm
      -- Now compose with projection Spk ‚Ü¶ Spk m
      -- The projection is linear, and D projects into {p | ‚àÄ u, 0 ‚â§ p u}
      let nonneg_fns := {q : S.U ‚Üí ‚Ñù | ‚àÄ v, 0 ‚â§ q v}
      let proj_fn : (S.M ‚Üí S.U ‚Üí ‚Ñù) ‚Üí (S.U ‚Üí ‚Ñù) := Œª spkFn => spkFn m
      have hD_proj : D ‚äÜ proj_fn ‚Åª¬π' nonneg_fns := by
        intro spkFn hspkFn
        simp only [Set.mem_preimage]
        exact hspkFn.1 m
      -- On D, normalize(Spk m) = Spk m, so entropy(normalize(Spk m)) = entropy(Spk m)
      have heq_on_D : ‚àÄ spkFn ‚àà D, entropy (normalize (spkFn m)) = entropy (spkFn m) := by
        intro spkFn hspkFn
        congr 1
        ext v
        exact hnorm_eq spkFn hspkFn m v
      -- Compose: spkFn ‚Ü¶ entropy(spkFn m) is concave
      have hcomp : ConcaveOn ‚Ñù (proj_fn ‚Åª¬π' nonneg_fns)
          (Œª spkFn => entropy (spkFn m)) := by
        -- projection is linear
        let proj_m : (S.M ‚Üí S.U ‚Üí ‚Ñù) ‚Üí‚Çó[‚Ñù] (S.U ‚Üí ‚Ñù) := {
          toFun := Œª spkFn => spkFn m
          map_add' := Œª _ _ => rfl
          map_smul' := Œª _ _ => rfl
        }
        exact hentropy_concave.comp_linearMap proj_m
      -- Restrict to D and use heq_on_D
      have hrestrict : ConcaveOn ‚Ñù D (Œª spkFn => entropy (spkFn m)) :=
        hcomp.subset hD_proj hD_convex
      exact hrestrict.congr (Œª spkFn hspkFn => (heq_on_D spkFn hspkFn).symm)
  -- E_VL on the simplex is linear in Spk (hence concave)
  have hE_concave : ConcaveOn ‚Ñù D (Œª Spk => E_VL S Spk L) := by
    unfold E_VL
    -- E_VL = Œ£_m Œ£_u P(m) ¬∑ normalize(Spk m)(u) ¬∑ utility(L, m, u)
    -- On D, normalize(Spk m)(u) = Spk m u, so:
    -- E_VL = Œ£_m Œ£_u P(m) ¬∑ Spk m u ¬∑ V(m,u)
    -- This is a linear function of Spk (weighted sum with fixed coefficients)
    -- Linear functions are concave
    have hlinear : ‚àÄ Spk ‚àà D, E_VL S Spk L =
        ‚àë m, ‚àë u, S.prior m * Spk m u * utility L m u := by
      intro Spk hSpk
      apply Finset.sum_congr rfl
      intro m _
      apply Finset.sum_congr rfl
      intro u _
      rw [hnorm_eq Spk hSpk m u]
    -- A linear function is concave
    apply ConcaveOn.congr _ (Œª Spk hSpk => (hlinear Spk hSpk).symm)
    -- The function Œ£_m Œ£_u c(m,u) * Spk m u is linear, hence concave
    apply concaveOn_finset_sum' hD_convex
    intro m _
    apply concaveOn_finset_sum' hD_convex
    intro u _
    -- Spk ‚Ü¶ c * Spk m u is linear (concave) for c = P(m) * V(m,u)
    -- The coefficient could be negative (if V < 0), but linear is still concave
    have hlinear_comp : ConcaveOn ‚Ñù D (Œª Spk => S.prior m * Spk m u * utility L m u) := by
      -- This is: (const) * (linear projection) which is affine, hence concave
      constructor
      ¬∑ exact hD_convex
      ¬∑ intro x _hx y _hy a b _ha _hb _hab
        -- Need: a ‚Ä¢ f(x) + b ‚Ä¢ f(y) ‚â§ f(a ‚Ä¢ x + b ‚Ä¢ y)
        -- For linear f, we have equality
        simp only [Pi.add_apply, Pi.smul_apply, smul_eq_mul]
        -- LHS = a * (prior * x m u * V) + b * (prior * y m u * V)
        -- RHS = prior * (a * x m u + b * y m u) * V
        -- These are equal by distributivity, so ‚â§ holds
        ring_nf
        exact le_refl _
    exact hlinear_comp
  -- G_Œ± = H_S + Œ± ¬∑ E_VL
  unfold G_Œ±
  have hŒ±_nonneg : 0 ‚â§ S.Œ± := S.Œ±_nonneg
  exact hH_concave.add (hE_concave.smul hŒ±_nonneg)

/--
Proposition 1, Part 2 (Zaslavsky et al.): G_Œ± is concave in L for fixed S.

Proof:
- H_S(Spk) does not depend on L ‚Üí constant ‚Üí concave
- E_VL = Œ£ P(m)¬∑S(u|m)¬∑log(L(u,m)) is weighted sum of logs
- log is concave on (0,‚àû) by `strictConcaveOn_log_Ioi`
- Weighted sum of concave functions (with non-negative weights) is concave
- G_Œ± = H_S + Œ±¬∑E_VL is sum of concave functions ‚Üí concave
-/
theorem G_Œ±_concave_in_L (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (hSpk_nonneg : ‚àÄ m u, 0 ‚â§ Spk m u) :
    ConcaveOn ‚Ñù {L | ‚àÄ u m, 0 < L u m}
      (Œª L => G_Œ± S Spk L) := by
  -- The domain {L | ‚àÄ u m, 0 < L u m} is convex
  have hD_convex : Convex ‚Ñù {L : S.U ‚Üí S.M ‚Üí ‚Ñù | ‚àÄ u m, 0 < L u m} := by
    intro x hx y hy a b ha hb hab
    simp only [Set.mem_setOf_eq] at hx hy ‚ä¢
    intro u m
    simp only [Pi.add_apply, Pi.smul_apply, smul_eq_mul]
    have h1 : 0 ‚â§ a * x u m := mul_nonneg ha (le_of_lt (hx u m))
    have h2 : 0 ‚â§ b * y u m := mul_nonneg hb (le_of_lt (hy u m))
    -- At least one of a, b is positive (since a + b = 1)
    by_cases ha' : 0 < a
    ¬∑ exact add_pos_of_pos_of_nonneg (mul_pos ha' (hx u m)) h2
    ¬∑ push_neg at ha'
      have ha_zero : a = 0 := le_antisymm ha' ha
      have hb_pos : 0 < b := by linarith
      rw [ha_zero, zero_mul, zero_add]
      exact mul_pos hb_pos (hy u m)
  -- Define the domain for clarity
  let D := {Lis : S.U ‚Üí S.M ‚Üí ‚Ñù | ‚àÄ u m, 0 < Lis u m}
  -- H_S is constant in L, hence concave
  have hH_concave : ConcaveOn ‚Ñù D (Œª _ => H_S S Spk) :=
    concaveOn_const (H_S S Spk) hD_convex
  -- For the E_VL term, we need log concavity
  -- utility Lis m u = log (Lis u m) when Lis u m > 0
  -- E_VL = Œ£_m Œ£_u P(m) ¬∑ norm_Spk(m,u) ¬∑ log(Lis u m)
  -- This is a weighted sum of logs, which is concave
  -- The full proof requires showing each log(Lis u m) is concave in Lis
  -- via composition with the projection Lis ‚Ü¶ Lis u m
  have hE_concave : ConcaveOn ‚Ñù D (Œª Lis => E_VL S Spk Lis) := by
    -- E_VL = Œ£_m Œ£_u w(m,u) ¬∑ utility(Lis, m, u)
    -- On D, utility(Lis, m, u) = log(Lis u m)
    -- Step 1: Show each (Lis ‚Ü¶ utility Lis m u) is concave on D
    have h_utility_concave : ‚àÄ m u, ConcaveOn ‚Ñù D (Œª Lis => utility Lis m u) := by
      intro m u
      -- On D, utility Lis m u = log (Lis u m)
      -- The evaluation map eval_{u,m} : Lis ‚Ü¶ Lis u m is linear
      -- log is concave on (0, ‚àû)
      -- Therefore log ‚àò eval is concave
      have hlog_concave : ConcaveOn ‚Ñù (Set.Ioi 0) Real.log :=
        strictConcaveOn_log_Ioi.concaveOn
      -- Define the evaluation functional
      let eval_um : (S.U ‚Üí S.M ‚Üí ‚Ñù) ‚Üí‚Çó[‚Ñù] ‚Ñù := {
        toFun := Œª Lis => Lis u m
        map_add' := Œª _ _ => rfl
        map_smul' := Œª _ _ => rfl
      }
      -- log ‚àò eval is concave on eval‚Åª¬π(Ioi 0)
      have hcomp : ConcaveOn ‚Ñù (eval_um ‚Åª¬π' Set.Ioi 0) (Real.log ‚àò eval_um) :=
        hlog_concave.comp_linearMap eval_um
      -- D ‚äÜ eval‚Åª¬π(Ioi 0) for all u, m
      have hsubset : D ‚äÜ eval_um ‚Åª¬π' Set.Ioi 0 := by
        intro Lis hLis
        simp only [Set.mem_preimage, Set.mem_Ioi]
        exact hLis u m
      -- Restrict to D
      have hcomp_D : ConcaveOn ‚Ñù D (Real.log ‚àò eval_um) :=
        hcomp.subset hsubset hD_convex
      -- On D, utility Lis m u = log(Lis u m) = (log ‚àò eval_um) Lis
      have heq : Set.EqOn (Œª Lis => utility Lis m u) (Real.log ‚àò eval_um) D := by
        intro Lis hLis
        simp only [Function.comp_apply, utility]
        rw [if_neg (not_le.mpr (hLis u m))]
        -- eval_um Lis = Lis u m by definition of eval_um
        rfl
      -- Transfer concavity via Set.EqOn
      exact hcomp_D.congr heq.symm
    -- Step 2: Weighted sum preserves concavity
    -- E_VL = Œ£_m Œ£_u (prior m * norm_Spk m u) * utility Lis m u
    unfold E_VL
    -- Rewrite as sum of weighted concave functions
    apply concaveOn_finset_sum' hD_convex
    intro m _
    apply concaveOn_finset_sum' hD_convex
    intro u _
    -- Weight is P(m) * normalize(Spk m)(u) ‚â• 0
    have hw_nonneg : 0 ‚â§ S.prior m * normalize (Spk m) u := by
      apply mul_nonneg (S.prior_nonneg m)
      unfold normalize Z
      split_ifs with hZ
      ¬∑ exact le_refl 0
      ¬∑ -- Spk m u / Œ£ Spk m ‚â• 0 when Spk m u ‚â• 0 and sum ‚â• 0
        apply div_nonneg (hSpk_nonneg m u)
        exact Finset.sum_nonneg (Œª v _ => hSpk_nonneg m v)
    exact (h_utility_concave m u).smul hw_nonneg
  -- G_Œ± = H_S + Œ± ¬∑ E_VL
  -- H_S is constant (concave), Œ± ¬∑ E_VL is concave (Œ± ‚â• 0)
  unfold G_Œ±
  have hŒ±_nonneg : 0 ‚â§ S.Œ± := S.Œ±_nonneg
  have hŒ±E_concave : ConcaveOn ‚Ñù D (Œª Lis => S.Œ± * E_VL S Spk Lis) :=
    hE_concave.smul hŒ±_nonneg
  exact hH_concave.add hŒ±E_concave


/-!
## KKT Conditions

For fixed L, the speaker optimization problem is:
  max_S  G_Œ±(S, L) = Œ£_m P(m) [Œ£_u negMulLog(S(u|m)) + Œ± ¬∑ Œ£_u S(u|m) ¬∑ V_L(m,u)]
  s.t.   Œ£_u S(u|m) = 1 for all m
         S(u|m) ‚â• 0

The Lagrangian is:
  L(S, Œª) = G_Œ±(S, L) - Œ£_m Œª_m (Œ£_u S(u|m) - 1)

First-order condition (for interior S(u|m) > 0):
  ‚àÇL/‚àÇS(u|m) = P(m) ¬∑ (‚àÇnegMulLog/‚àÇs + Œ± ¬∑ V_L(m,u)) - Œª_m = 0
             = P(m) ¬∑ (-log S(u|m) - 1 + Œ± ¬∑ log L(m|u)) - Œª_m = 0

Solving for S(u|m):
  log S(u|m) = Œ± ¬∑ log L(m|u) - 1 - Œª_m/P(m)
  S(u|m) = L(m|u)^Œ± ¬∑ exp(-1 - Œª_m/P(m))
  S(u|m) ‚àù L(m|u)^Œ±

This is the RSA speaker update. By concavity of G_Œ± in S,
this stationary point is the global maximum.

Mathlib lemmas used:
- `Real.hasDerivAt_negMulLog`: d/dx(negMulLog x) = -log x - 1
- `Real.deriv_negMulLog`: Same in deriv form
- Concavity from Part 6 ensures stationary point is maximum
-/

/--
The per-meaning objective for the speaker optimization.

For fixed meaning m and listener L, this is the function the speaker maximizes:
  f_m(s) = Œ£_u [negMulLog(s_u) + Œ± ¬∑ s_u ¬∑ log L(m|u)]
-/
noncomputable def speakerObjective (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (m : S.M) (s : S.U ‚Üí ‚Ñù) : ‚Ñù :=
  ‚àë u, (Real.negMulLog (s u) + S.Œ± * s u * utility L m u)

/--
Derivative of the per-meaning speaker objective with respect to s_u.

Using Mathlib's `Real.deriv_negMulLog`:
  ‚àÇ/‚àÇs_u [negMulLog(s_u) + Œ± ¬∑ s_u ¬∑ V] = -log(s_u) - 1 + Œ± ¬∑ V
-/
theorem deriv_speakerObjective_component (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (m : S.M) (u : S.U) (s_u : ‚Ñù) (hs : s_u ‚â† 0) (_hs_pos : 0 < s_u)
    (_hL : 0 < L u m) :
    HasDerivAt (Œª x => Real.negMulLog x + S.Œ± * x * utility L m u)
               (-Real.log s_u - 1 + S.Œ± * utility L m u)
               s_u := by
  -- negMulLog has derivative -log x - 1 by Real.hasDerivAt_negMulLog
  have h1 : HasDerivAt Real.negMulLog (-Real.log s_u - 1) s_u :=
    Real.hasDerivAt_negMulLog hs
  -- The linear term Œ± * x * V has derivative Œ± * V
  have h2 : HasDerivAt (Œª x => S.Œ± * x * utility L m u) (S.Œ± * utility L m u) s_u := by
    have hid : HasDerivAt (Œª x => x) 1 s_u := hasDerivAt_id s_u
    have hmul : HasDerivAt (Œª x => S.Œ± * x) S.Œ± s_u := by
      simpa using hid.const_mul S.Œ±
    exact hmul.mul_const (utility L m u)
  -- Sum of derivatives: (-log s_u - 1) + (Œ± * V) = -log s_u - 1 + Œ± * V
  exact h1.add h2

/--
The RSA speaker update satisfies the first-order optimality condition.

At s_u = L(m|u)^Œ± (normalized), the derivative equals a constant across all u
(the Lagrange multiplier). This is the KKT stationarity condition.

For s_u ‚àù L(m|u)^Œ±, we have:
  -log s_u - 1 + Œ±¬∑log L(m|u) = -log(L(m|u)^Œ± / Z) - 1 + Œ±¬∑log L(m|u)
                               = -Œ±¬∑log L(m|u) + log Z - 1 + Œ±¬∑log L(m|u)
                               = log Z - 1  (constant!)

So all components have the same derivative value, satisfying KKT.
-/
theorem rsa_speaker_satisfies_foc (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (m : S.M) (hL : ‚àÄ u, 0 < L u m) :
    let s_rsa := Œª u => speakerScore S L m u
    let Zsum := ‚àë u, s_rsa u
    Zsum ‚â† 0 ‚Üí
    ‚àÄ u, s_rsa u / Zsum > 0 ‚Üí
         -- The derivative at s_norm: -log(s_norm) - 1 + Œ±¬∑V
         -- For RSA: s_norm = L(m|u)^Œ± / Z, so -log(s_norm) = -Œ±¬∑log L(m|u) + log Z
         -- Therefore: -log(s_norm) - 1 + Œ±¬∑log L(m|u) = log Z - 1 (constant!)
         -Real.log (s_rsa u / Zsum) - 1 + S.Œ± * utility L m u = Real.log Zsum - 1 := by
  intro s_rsa Zsum hZ u hs_pos
  -- Expand utility: V(u,m) = log L(m|u) when L > 0
  have hutil : utility L m u = Real.log (L u m) := by
    simp only [utility]
    rw [if_neg (not_le.mpr (hL u))]
  rw [hutil]
  -- s_rsa u = speakerScore = L(m|u)^Œ± (when L(m|u) > 0)
  have hspk : s_rsa u = (L u m).rpow S.Œ± := by
    -- s_rsa is definitionally speakerScore S L m, so we need to show
    -- speakerScore S L m u = (L u m).rpow S.Œ±
    show speakerScore S L m u = (L u m).rpow S.Œ±
    simp only [speakerScore]
    rw [if_neg (not_le.mpr (hL u))]
  rw [hspk]
  -- Positivity facts
  have hLpos : 0 < L u m := hL u
  have hrpow_pos : 0 < (L u m).rpow S.Œ± := Real.rpow_pos_of_pos hLpos S.Œ±
  have hZpos : 0 < Zsum := by
    by_contra h
    push_neg at h
    have hsum_nonneg : 0 ‚â§ Zsum := Finset.sum_nonneg (Œª v _ => by
      show 0 ‚â§ speakerScore S L m v
      simp only [speakerScore]
      split_ifs with hv
      ¬∑ exact le_refl 0
      ¬∑ push_neg at hv
        exact le_of_lt (Real.rpow_pos_of_pos hv S.Œ±))
    exact hZ (le_antisymm h hsum_nonneg)
  -- -log(L^Œ± / Z) = -log(L^Œ±) + log Z = -Œ±¬∑log L + log Z
  rw [Real.log_div (ne_of_gt hrpow_pos) (ne_of_gt hZpos)]
  -- log(x.rpow Œ±) = Œ± * log x for x > 0
  have hlog_rpow : Real.log ((L u m).rpow S.Œ±) = S.Œ± * Real.log (L u m) :=
    Real.log_rpow hLpos S.Œ±
  rw [hlog_rpow]
  ring

/-!
### The KKT Gap

The standard convex optimization result needed is:

Theorem (KKT sufficiency for concave functions):
If f is concave on a convex set K, and x* ‚àà K satisfies the KKT conditions
(gradient equals Lagrange multiplier times constraint gradient), then x* is
a global maximum of f over K.

Proof idea (not formalized):
1. Concavity gives: f(y) ‚â§ f(x*) + ‚àáf(x*)¬∑(y - x*)
2. KKT on simplex: ‚àáf(x*) = Œª¬∑ùüô  (constant gradient)
3. For feasible y: ùüô¬∑(y - x*) = Œ£y - Œ£x* = 1 - 1 = 0
4. Therefore: f(y) ‚â§ f(x*) + Œª¬∑0 = f(x*)

Mathlib does not directly provide this result. The pieces exist:
- `ConcaveOn` provides the concavity inequality
- `HasFDerivAt` provides derivatives
- But connecting them to KKT for simplex constraints is not formalized

For now, we state theorems with the conclusion as hypothesis where needed.
A full formalization would require:
1. Formalizing KKT conditions for simplex-constrained optimization
2. Proving KKT sufficiency for concave objectives
3. Verifying RSA updates satisfy KKT

This is a significant formalization project beyond the scope of the current work.
-/

/--
AXIOM: KKT sufficiency for concave functions on the simplex.

This is a standard convex optimization result:
If f is concave on the simplex Œî = {x | ‚àÄi, x_i ‚â• 0, Œ£x_i = 1}, and x* ‚àà Œî
satisfies the KKT first-order conditions, then x* is a global maximum.

Standard proof (not formalized in Mathlib):
1. Concavity: f(y) ‚â§ f(x*) + ‚àáf(x*)¬∑(y - x*) for all y ‚àà Œî
2. KKT on simplex: ‚àáf(x*) = Œª¬∑ùüô (constant gradient when optimal)
3. Feasibility: ùüô¬∑(y - x*) = 1 - 1 = 0 for y, x* ‚àà Œî
4. Therefore: f(y) ‚â§ f(x*) for all feasible y

We axiomatize this as it requires formalizing:
- KKT conditions for inequality-constrained optimization
- The simplex as a constraint set
- Connecting ConcaveOn to first-order Taylor bounds

References:
- Boyd & Vandenberghe (2004) "Convex Optimization" Section 5.5.3
- Zaslavsky et al. (2020) implicitly use this in their convergence proof
-/
axiom kkt_sufficiency_for_concave_on_simplex {Œ± : Type*} [Fintype Œ±]
    {f : (Œ± ‚Üí ‚Ñù) ‚Üí ‚Ñù} {x_star : Œ± ‚Üí ‚Ñù}
    (hconcave : ConcaveOn ‚Ñù {x | (‚àÄ i, 0 ‚â§ x i) ‚àß ‚àë i, x i = 1} f)
    (hsum_star : ‚àë i, x_star i = 1)
    (hpos_star : ‚àÄ i, 0 ‚â§ x_star i)
    (hfoc : ‚àÉ lam : ‚Ñù, ‚àÄ i, 0 < x_star i ‚Üí deriv (f ‚àò (Œª t => Function.update x_star i t)) (x_star i) = lam) :
    ‚àÄ y : Œ± ‚Üí ‚Ñù, (‚àÄ i, 0 ‚â§ y i) ‚Üí ‚àë i, y i = 1 ‚Üí f y ‚â§ f x_star

/--
AXIOM: KKT sufficiency for concave functions on the positive orthant.

Similar to simplex case but for the domain {L | ‚àÄ u m, 0 < L u m}.
The RSA listener update L(m|u) ‚àù prior(m) ¬∑ S(u|m) satisfies KKT
and G_Œ± is concave in L.
-/
axiom kkt_sufficiency_for_concave_on_positive {Œ≤ : Type*} [Fintype Œ≤]
    {f : (Œ≤ ‚Üí ‚Ñù) ‚Üí ‚Ñù} {x_star : Œ≤ ‚Üí ‚Ñù}
    (hconcave : ConcaveOn ‚Ñù {x | ‚àÄ i, 0 < x i} f)
    (hpos_star : ‚àÄ i, 0 < x_star i)
    (hfoc : ‚àÄ i, deriv (f ‚àò (Œª t => Function.update x_star i t)) (x_star i) = 0) :
    ‚àÄ y : Œ≤ ‚Üí ‚Ñù, (‚àÄ i, 0 < y i) ‚Üí f y ‚â§ f x_star

/--
AXIOM: RSA Speaker Update is G_Œ±-Optimal (Zaslavsky et al. Eq. 7).

For fixed listener L, the RSA speaker update S(u|m) ‚àù L(m|u)^Œ±
achieves the maximum of G_Œ± over all valid speaker distributions.

Justification:
1. `G_Œ±_concave_in_S`: G_Œ± is concave in S on the simplex
2. `rsa_speaker_satisfies_foc`: RSA speaker satisfies KKT first-order conditions
3. Standard result: KKT + concave ‚üπ global optimum

The axiom bridges the type-theoretic gap between the abstract simplex
optimization result and the specific RSA formulation with
S.M ‚Üí S.U ‚Üí ‚Ñù functions.
-/
axiom rsa_speaker_maximizes_G_Œ± (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (hL : ‚àÄ u m, 0 < L u m)
    (Spk' : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (hSpk'_sum : ‚àÄ m, ‚àë u, Spk' m u = 1)
    (hSpk'_nonneg : ‚àÄ m u, 0 ‚â§ Spk' m u) :
    G_Œ± S Spk' L ‚â§ G_Œ± S (speakerUpdate S L) L

/--
AXIOM: RSA Listener Update is G_Œ±-Optimal (Zaslavsky et al. Eq. 8).

For fixed speaker S, the RSA listener L(m|u) ‚àù P(m) ¬∑ S(u|m)
achieves the maximum of G_Œ± over all valid listener distributions.

Justification:
1. `G_Œ±_concave_in_L`: G_Œ± is concave in L on the positive orthant
2. KKT conditions: ‚àÇG_Œ±/‚àÇL(m,u) = Œ± ¬∑ P(m) ¬∑ S(u|m) / L(m,u) - Œ± ¬∑ (normalization)
   Setting to zero gives L(m|u) ‚àù P(m) ¬∑ S(u|m)
3. Standard result: KKT + concave ‚üπ global optimum
-/
axiom rsa_listener_maximizes_G_Œ± (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (hSpk : ‚àÄ m u, 0 < Spk m u)
    (L' : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (hL'_sum : ‚àÄ u, ‚àë m, L' u m = 1)
    (hL'_pos : ‚àÄ u m, 0 < L' u m) :
    G_Œ± S Spk L' ‚â§ G_Œ± S Spk (listenerUpdate S Spk)

/--
The RSA speaker update maximizes G_Œ± (Zaslavsky et al. Eq. 7).

For fixed listener L_{t-1}, the RSA speaker update S_t = argmax_S G_Œ±[S, L_{t-1}].
Follows directly from `rsa_speaker_maximizes_G_Œ±`.
-/
theorem speaker_update_maximizes_G (S : RSAScenarioR) (L : S.U ‚Üí S.M ‚Üí ‚Ñù)
    (hL : ‚àÄ u m, 0 < L u m) :
    ‚àÄ Spk', (‚àÄ m, ‚àë u, Spk' m u = 1) ‚Üí (‚àÄ m u, 0 ‚â§ Spk' m u) ‚Üí
      G_Œ± S Spk' L ‚â§ G_Œ± S (speakerUpdate S L) L := by
  intro Spk' hSpk'_sum hSpk'_nonneg
  exact rsa_speaker_maximizes_G_Œ± S L hL Spk' hSpk'_sum hSpk'_nonneg

/--
The RSA listener update maximizes G_Œ± (Zaslavsky et al. Eq. 8).

For fixed speaker S_t, the RSA listener update L_t = argmax_L G_Œ±[S_t, L].
Follows directly from `rsa_listener_maximizes_G_Œ±`.
-/
theorem listener_update_maximizes_G (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (hSpk : ‚àÄ m u, 0 < Spk m u) :
    ‚àÄ L', (‚àÄ u, ‚àë m, L' u m = 1) ‚Üí (‚àÄ u m, 0 < L' u m) ‚Üí
      G_Œ± S Spk L' ‚â§ G_Œ± S Spk (listenerUpdate S Spk) := by
  intro L' hL'_sum hL'_pos
  exact rsa_listener_maximizes_G_Œ± S Spk hSpk L' hL'_sum hL'_pos


/--
G_Œ± Monotonicity (Zaslavsky et al. Proposition 1, Eq. 9).

RSA dynamics implement alternating maximization of G_Œ±.
For every t ‚â• 1:
  G_Œ±[S_t, L_{t-1}] ‚â§ G_Œ±[S_t, L_t] ‚â§ G_Œ±[S_{t+1}, L_t]

Proof: Chain speaker and listener optimality.
- Step 1: G_Œ±[S_n, L_n] ‚â§ G_Œ±[S_{n+1}, L_n] by speaker_update_maximizes_G
- Step 2: G_Œ±[S_{n+1}, L_n] ‚â§ G_Œ±[S_{n+1}, L_{n+1}] by listener_update_maximizes_G
-/
theorem G_Œ±_monotone (S : RSAScenarioR) [Nonempty S.U] (n : ‚Ñï)
    (h_pos : ‚àÄ t u m, 0 < (iterateRSA S t).listener u m)
    (h_Spk_pos : ‚àÄ t m u, 0 < (iterateRSA S t).speaker m u)
    (h_Spk_sum : ‚àÄ t m, ‚àë u, (iterateRSA S t).speaker m u = 1)
    (h_L_sum : ‚àÄ t u, ‚àë m, (iterateRSA S t).listener u m = 1) :
    G_Œ± S (iterateRSA S n).speaker (iterateRSA S n).listener ‚â§
    G_Œ± S (iterateRSA S (n+1)).speaker (iterateRSA S (n+1)).listener := by
  -- Notation: state_n = iterateRSA n, state_{n+1} = iterateRSA (n+1)
  let state_n := iterateRSA S n
  let state_n1 := iterateRSA S (n+1)
  -- Key: state_{n+1} = stepRSA state_n
  -- So: state_{n+1}.speaker = speakerUpdate state_n.listener
  --     state_{n+1}.listener = listenerUpdate state_{n+1}.speaker
  have hstep : state_n1 = stepRSA S state_n := Function.iterate_succ_apply' (stepRSA S) n _
  -- Step 1: G_Œ±(S_n, L_n) ‚â§ G_Œ±(S_{n+1}, L_n)  [speaker improved]
  have hSpk_nonneg : ‚àÄ m u, 0 ‚â§ state_n.speaker m u :=
    Œª m u => le_of_lt (h_Spk_pos n m u)
  have h_spk_eq : state_n1.speaker = speakerUpdate S state_n.listener := by
    simp only [hstep, stepRSA]
  have h1 : G_Œ± S state_n.speaker state_n.listener ‚â§ G_Œ± S state_n1.speaker state_n.listener := by
    rw [h_spk_eq]
    exact speaker_update_maximizes_G S state_n.listener (h_pos n)
      state_n.speaker (h_Spk_sum n) hSpk_nonneg
  -- Step 2: G_Œ±(S_{n+1}, L_n) ‚â§ G_Œ±(S_{n+1}, L_{n+1})  [listener improved]
  -- Helper: speaker score is positive when listener probability is positive
  have hScore_pos : ‚àÄ m u, 0 < speakerScore S state_n.listener m u := by
    intro m u
    simp only [speakerScore]
    have hLpos : 0 < state_n.listener u m := h_pos n u m
    rw [if_neg (not_le.mpr hLpos)]
    exact Real.rpow_pos_of_pos hLpos S.Œ±
  have hSpk'_pos : ‚àÄ m u, 0 < state_n1.speaker m u := by
    intro m u
    rw [h_spk_eq]
    -- speakerUpdate S L m u = speakerScore S L m u (by definition)
    unfold speakerUpdate
    exact hScore_pos m u
  have h_lis_eq : state_n1.listener = listenerUpdate S state_n1.speaker := by
    simp only [hstep, stepRSA]
  have h2 : G_Œ± S state_n1.speaker state_n.listener ‚â§ G_Œ± S state_n1.speaker state_n1.listener := by
    rw [h_lis_eq]
    exact listener_update_maximizes_G S state_n1.speaker hSpk'_pos
      state_n.listener (h_L_sum n) (h_pos n)
  exact le_trans h1 h2

/--
Corollary: RSA Converges (Zaslavsky et al. Footnote 1).

From the paper: "Because GŒ± is bounded from above, it follows that RSA iterations
are guaranteed to converge."

Proof by the Monotone Convergence Theorem:
- G_Œ± is monotonically non-decreasing (by `G_Œ±_monotone`)
- G_Œ± is bounded above by log |U| (max entropy)
- Therefore the sequence G_Œ±(S_t, L_t) converges
-/
theorem RSA_converges (S : RSAScenarioR) [Nonempty S.U]
    (h_pos : ‚àÄ t u m, 0 < (iterateRSA S t).listener u m)
    (h_Spk_pos : ‚àÄ t m u, 0 < (iterateRSA S t).speaker m u)
    (h_Spk_sum : ‚àÄ t m, ‚àë u, (iterateRSA S t).speaker m u = 1)
    (h_L_sum : ‚àÄ t u, ‚àë m, (iterateRSA S t).listener u m = 1) :
    ‚àÉ L : ‚Ñù, Filter.Tendsto
      (Œª n => G_Œ± S (iterateRSA S n).speaker (iterateRSA S n).listener)
      Filter.atTop
      (nhds L) := by
  -- Proof: Monotone bounded sequences converge (Monotone Convergence Theorem)
  -- 1. Monotonicity: from G_Œ±_monotone
  -- 2. Bounded above: from G_Œ±_bounded
  -- 3. Apply tendsto_atTop_iSup
  --
  -- Technical gap: Need to show the sequence is monotone using the inductive step
  -- This follows from G_Œ±_monotone but requires careful bookkeeping
  sorry


/--
G_Œ± is bounded above.

Proof sketch:
- H_S = weighted entropy ‚â§ log|U| (max entropy)
- E_VL = expected log utility, bounded by log(max L value) for normalized listeners
- G_Œ± = H_S + Œ±¬∑E_VL is bounded above

The exact bound depends on L. For RSA listener L(m|u) ‚àù P(m)S(u|m),
E_VL is bounded by the prior distribution's support.
-/
axiom G_Œ±_bounded (S : RSAScenarioR) : ‚àÉ B : ‚Ñù, ‚àÄ Spk L,
    (‚àÄ m, ‚àë u, Spk m u = 1) ‚Üí (‚àÄ m u, 0 ‚â§ Spk m u) ‚Üí G_Œ± S Spk L ‚â§ B

/-- G_Œ± is bounded above by log |U| (simplified statement). -/
theorem G_Œ±_bounded_above (S : RSAScenarioR) (Spk : S.M ‚Üí S.U ‚Üí ‚Ñù)
    (L : S.U ‚Üí S.M ‚Üí ‚Ñù) (hSpk : ‚àÄ m, ‚àë u, Spk m u = 1) (hSpk_pos : ‚àÄ m u, 0 ‚â§ Spk m u) :
    G_Œ± S Spk L ‚â§ log (Fintype.card S.U) + S.Œ± * 0 := by
  -- This is a simplification; full proof uses entropy bound + utility bound
  have ‚ü®B, hB‚ü© := G_Œ±_bounded S
  -- The RHS is log|U| which is actually the entropy bound
  -- Full proof would show H_S ‚â§ log|U| and E_VL ‚â§ 0 for standard RSA utility
  sorry

/-- Check if RSA has Œµ-converged. -/
def ŒµConverged (S : RSAScenarioR) (t : ‚Ñï) (Œµ : ‚Ñù) : Prop :=
  |G_Œ± S (iterateRSA S (t+1)).speaker (iterateRSA S (t+1)).listener -
   G_Œ± S (iterateRSA S t).speaker (iterateRSA S t).listener| < Œµ

/-- Eventually Œµ-converged: For any Œµ > 0, RSA is eventually Œµ-converged. -/
theorem eventually_ŒµConverged (S : RSAScenarioR) [Nonempty S.U] (Œµ : ‚Ñù) (hŒµ : 0 < Œµ)
    (h_pos : ‚àÄ t u m, 0 < (iterateRSA S t).listener u m)
    (h_Spk_pos : ‚àÄ t m u, 0 < (iterateRSA S t).speaker m u)
    (h_Spk_sum : ‚àÄ t m, ‚àë u, (iterateRSA S t).speaker m u = 1)
    (h_L_sum : ‚àÄ t u, ‚àë m, (iterateRSA S t).listener u m = 1) :
    ‚àÉ T, ‚àÄ t, T ‚â§ t ‚Üí ŒµConverged S t Œµ := by
  -- Proof: Convergent sequences are Cauchy, so differences become small
  -- 1. From RSA_converges, the sequence converges to some limit L
  -- 2. f(n+1) - f(n) ‚Üí L - L = 0 as n ‚Üí ‚àû
  -- 3. By Metric.tendsto_atTop, for any Œµ > 0, eventually |f(n+1) - f(n)| < Œµ
  --
  -- Technical gap: The subtraction of limits and bookkeeping
  sorry

end RSA.Convergence
