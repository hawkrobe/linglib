import Linglib.Core.RationalAction
import Mathlib.Order.Filter.Basic
import Mathlib.Topology.Order.Basic
import Mathlib.Topology.Order.Real
import Mathlib.Analysis.SpecialFunctions.Pow.Real
import Mathlib.Analysis.SpecialFunctions.Log.Deriv
import Mathlib.Topology.Algebra.InfiniteSum.Real

/-!
# Softmax Function: Limit Behavior

Œ± ‚Üí 0: uniform, Œ± ‚Üí ‚àû: argmax, Œ± ‚Üí -‚àû: argmin.
-/

namespace Softmax

open Core Real BigOperators Finset Filter Topology

variable {Œπ : Type*} [Fintype Œπ] [DecidableEq Œπ]

/-- The set of indices achieving the maximum score. -/
def argmaxSet (s : Œπ ‚Üí ‚Ñù) : Set Œπ :=
  {i | ‚àÄ j, s j ‚â§ s i}

/-- The set of indices achieving the minimum score. -/
def argminSet (s : Œπ ‚Üí ‚Ñù) : Set Œπ :=
  {i | ‚àÄ j, s i ‚â§ s j}

/-- Maximum score value. -/
noncomputable def maxScore [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  ‚®Ü i, s i

/-- Minimum score value. -/
noncomputable def minScore [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  ‚®Ö i, s i

/-- Fact 4: As Œ± ‚Üí 0, softmax converges to uniform distribution. -/
theorem tendsto_softmax_zero [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) (i : Œπ) :
    Tendsto (Œª Œ± => softmax s Œ± i) (ùìù 0) (ùìù (1 / Fintype.card Œπ)) := by
  have h : softmax s 0 i = 1 / Fintype.card Œπ := by
    have := softmax_zero s
    simp only [this]
  rw [‚Üê h]
  apply Continuous.tendsto
  -- softmax Œ± i = exp(Œ± * s i) / Œ£‚±º exp(Œ± * s j) is continuous in Œ±
  -- Numerator: exp is continuous, mul is continuous
  -- Denominator: finite sum of continuous functions, always positive
  simp only [softmax]
  apply Continuous.div
  ¬∑ exact continuous_exp.comp (continuous_mul_right (s i))
  ¬∑ apply continuous_finset_sum
    intro j _
    exact continuous_exp.comp (continuous_mul_right (s j))
  ¬∑ intro Œ±
    exact partitionFn_ne_zero s Œ±

/-- The ratio of non-max to max probability vanishes as Œ± ‚Üí ‚àû. -/
theorem softmax_ratio_tendsto_zero [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i j : Œπ) (hij : s i < s j) :
    Tendsto (Œª Œ± => softmax s Œ± i / softmax s Œ± j) atTop (ùìù 0) := by
  simp only [softmax_odds]
  -- exp(Œ± * (s_i - s_j)) ‚Üí 0 when s_i < s_j
  have h : s i - s j < 0 := by linarith
  -- Use Mathlib: exp(x) ‚Üí 0 as x ‚Üí -‚àû, and c * Œ± ‚Üí -‚àû when c < 0
  have hconv : Tendsto (Œª Œ± => (s i - s j) * Œ±) atTop atBot :=
    tendsto_id.const_mul_atTop_of_neg h
  -- Rewrite to match: Œ± * (s i - s j) = (s i - s j) * Œ±
  have heq : (Œª Œ± => exp (Œ± * (s i - s j))) = (Œª Œ± => exp ((s i - s j) * Œ±)) := by
    ext Œ±; ring_nf
  rw [heq]
  exact tendsto_exp_atBot.comp hconv

/-- At the maximum, softmax ‚Üí 1 as Œ± ‚Üí ‚àû. Helper lemma. -/
theorem tendsto_softmax_infty_at_max [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_unique : ‚àÄ j, j ‚â† i_max ‚Üí s j < s i_max) :
    Tendsto (Œª Œ± => softmax s Œ± i_max) atTop (ùìù 1) := by
  -- Simple proof: softmax sums to 1, and all non-max terms ‚Üí 0
  -- So: softmax_max = 1 - Œ£_{j‚â†max} softmax_j ‚Üí 1 - 0 = 1
  set S := Finset.univ.filter (Œª j : Œπ => j ‚â† i_max) with hS
  have hsum : ‚àÄ Œ±, softmax s Œ± i_max = 1 - ‚àë j ‚àà S, softmax s Œ± j := by
    intro Œ±
    have h := softmax_sum_eq_one s Œ±
    rw [‚Üê Finset.sum_filter_add_sum_filter_not (s := Finset.univ) (p := (¬∑ = i_max))] at h
    have hsimp : Finset.filter (¬∑ = i_max) Finset.univ = {i_max} := by
      ext x
      simp only [Finset.mem_filter, Finset.mem_univ, true_and, Finset.mem_singleton]
    rw [hsimp, Finset.sum_singleton] at h
    have hne : Finset.filter (Œª x => ¬¨x = i_max) Finset.univ = S := by
      ext x
      simp only [Finset.mem_filter, Finset.mem_univ, true_and, ne_eq, hS]
    rw [hne] at h
    linarith
  -- First show each softmax_j ‚Üí 0 for j ‚â† max
  have heach : ‚àÄ j ‚àà S, Tendsto (Œª Œ± => softmax s Œ± j) atTop (ùìù 0) := by
    intro j hj
    rw [hS, Finset.mem_filter] at hj
    -- softmax_j ‚â§ (softmax_j / softmax_max) because softmax_max ‚â§ 1
    have hratio := softmax_ratio_tendsto_zero s j i_max (h_unique j hj.2)
    have hbound : ‚àÄ Œ±, softmax s Œ± j ‚â§ softmax s Œ± j / softmax s Œ± i_max := by
      intro Œ±
      have h1 : softmax s Œ± i_max ‚â§ 1 := softmax_le_one s Œ± i_max
      have hpos : 0 < softmax s Œ± i_max := softmax_pos s Œ± i_max
      have hinv : 1 ‚â§ 1 / softmax s Œ± i_max := (one_le_div hpos).mpr h1
      calc softmax s Œ± j = softmax s Œ± j * 1 := by ring
        _ ‚â§ softmax s Œ± j * (1 / softmax s Œ± i_max) :=
            mul_le_mul_of_nonneg_left hinv (softmax_nonneg s Œ± j)
        _ = softmax s Œ± j / softmax s Œ± i_max := by ring
    exact tendsto_of_tendsto_of_tendsto_of_le_of_le tendsto_const_nhds hratio
      (Œª Œ± => softmax_nonneg s Œ± j) hbound
  -- Sum of terms each ‚Üí 0 is ‚Üí 0
  have hsum_zero : Tendsto (Œª Œ± => ‚àë j ‚àà S, softmax s Œ± j) atTop (ùìù 0) := by
    have h := tendsto_finset_sum S (Œª j hj => heach j hj)
    simp only [Finset.sum_const_zero] at h
    exact h
  -- 1 - sum ‚Üí 1 - 0 = 1
  have hmain : Tendsto (Œª Œ± => 1 - ‚àë j ‚àà S, softmax s Œ± j) atTop (ùìù (1 : ‚Ñù)) := by
    have htend : Tendsto (Œª Œ± => (1 : ‚Ñù) - ‚àë j ‚àà S, softmax s Œ± j) atTop (ùìù ((1 : ‚Ñù) - 0)) :=
      tendsto_const_nhds.sub hsum_zero
    simp only [sub_zero] at htend
    exact htend
  exact hmain.congr (Œª Œ± => (hsum Œ±).symm)

/-- When there's a unique maximum, softmax concentrates on it as Œ± ‚Üí ‚àû. -/
theorem tendsto_softmax_infty_unique_max [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_unique : ‚àÄ j, j ‚â† i_max ‚Üí s j < s i_max) (i : Œπ) :
    Tendsto (Œª Œ± => softmax s Œ± i) atTop
      (ùìù (if i = i_max then 1 else 0)) := by
  by_cases h : i = i_max
  ¬∑ -- i = i_max, so we need softmax ‚Üí 1
    rw [if_pos h, h]
    exact tendsto_softmax_infty_at_max s i_max h_unique
  ¬∑ -- i ‚â† i_max, so we need softmax ‚Üí 0
    rw [if_neg h]
    have hi : s i < s i_max := h_unique i h
    have hratio := softmax_ratio_tendsto_zero s i i_max hi
    have hbound : ‚àÄ Œ±, softmax s Œ± i ‚â§ softmax s Œ± i / softmax s Œ± i_max := by
      intro Œ±
      have h1 : softmax s Œ± i_max ‚â§ 1 := softmax_le_one s Œ± i_max
      have hpos : 0 < softmax s Œ± i_max := softmax_pos s Œ± i_max
      have hinv : 1 ‚â§ 1 / softmax s Œ± i_max := (one_le_div hpos).mpr h1
      calc softmax s Œ± i = softmax s Œ± i * 1 := by ring
        _ ‚â§ softmax s Œ± i * (1 / softmax s Œ± i_max) :=
            mul_le_mul_of_nonneg_left hinv (softmax_nonneg s Œ± i)
        _ = softmax s Œ± i / softmax s Œ± i_max := by ring
    exact tendsto_of_tendsto_of_tendsto_of_le_of_le tendsto_const_nhds hratio
      (Œª Œ± => softmax_nonneg s Œ± i) hbound

/-- Log-probability difference grows unboundedly. -/
theorem log_softmax_ratio_tendsto [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i j : Œπ) (hij : s i < s j) :
    Tendsto (Œª Œ± => log (softmax s Œ± j / softmax s Œ± i)) atTop atTop := by
  simp only [log_softmax_odds]
  -- Œ± * (s_j - s_i) ‚Üí ‚àû when s_j > s_i
  have h : 0 < s j - s i := by linarith
  -- Rewrite: Œ± * (s j - s i) = (s j - s i) * Œ±
  have heq : (Œª Œ± => Œ± * (s j - s i)) = (Œª Œ± => (s j - s i) * Œ±) := by
    ext Œ±; ring
  rw [heq]
  exact tendsto_id.const_mul_atTop h

/-- As Œ± ‚Üí -‚àû, softmax concentrates on the minimum. -/
theorem tendsto_softmax_neg_infty_unique_min [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_min : Œπ) (h_unique : ‚àÄ j, j ‚â† i_min ‚Üí s i_min < s j) (i : Œπ) :
    Tendsto (Œª Œ± => softmax s Œ± i) atBot
      (ùìù (if i = i_min then 1 else 0)) := by
  -- Use: softmax(s, Œ±) = softmax(-s, -Œ±)
  -- As Œ± ‚Üí -‚àû, this is like softmax(-s, Œ≤) as Œ≤ ‚Üí ‚àû
  -- And -s has unique max at i_min (where s has unique min)
  have hconv : ‚àÄ Œ±, softmax s Œ± = softmax (Œª j => -s j) (-Œ±) := by
    intro Œ±
    funext j
    unfold Core.softmax
    congr 1
    ¬∑ congr 1; ring
    ¬∑ apply Finset.sum_congr rfl; intro k _; congr 1; ring
  simp_rw [hconv]
  have hneg : ‚àÄ j, j ‚â† i_min ‚Üí -s j < -s i_min := by
    intro j hj
    exact neg_lt_neg (h_unique j hj)
  have := tendsto_softmax_infty_unique_max (Œª j => -s j) i_min hneg i
  exact this.comp tendsto_neg_atBot_atTop

/-- The IBR limit: hardmax selector. -/
noncomputable def hardmax [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_unique : ‚àÄ j, j ‚â† i_max ‚Üí s j < s i_max) : Œπ ‚Üí ‚Ñù :=
  Œª i => if i = i_max then 1 else 0

/-- Softmax converges to hardmax as Œ± ‚Üí ‚àû (when maximum is unique). -/
theorem softmax_tendsto_hardmax [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_unique : ‚àÄ j, j ‚â† i_max ‚Üí s j < s i_max) :
    ‚àÄ i, Tendsto (Œª Œ± => softmax s Œ± i) atTop
      (ùìù (hardmax s i_max h_unique i)) := by
  intro i
  simp only [hardmax]
  exact tendsto_softmax_infty_unique_max s i_max h_unique i

/-- Shannon entropy of a distribution. -/
noncomputable def entropy [Nonempty Œπ] (p : Œπ ‚Üí ‚Ñù) : ‚Ñù :=
  -‚àë i : Œπ, p i * log (p i)

/-- Maximum possible entropy (uniform distribution). -/
noncomputable def maxEntropy (Œπ : Type*) [Fintype Œπ] : ‚Ñù :=
  log (Fintype.card Œπ)

/-- As Œ± ‚Üí 0, entropy of softmax approaches maximum. -/
theorem entropy_tendsto_max [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù) :
    Tendsto (Œª Œ± => entropy (softmax s Œ±)) (ùìù 0) (ùìù (maxEntropy Œπ)) := by
  -- entropy ‚àò softmax is continuous in Œ±, so the limit equals the value at Œ± = 0
  have hval : entropy (softmax s 0) = maxEntropy Œπ := by
    unfold entropy maxEntropy
    simp_rw [softmax_zero s]
    simp only [Finset.sum_const, Finset.card_univ, nsmul_eq_mul, one_div,
               Real.log_inv, neg_neg]
    have hn : (Fintype.card Œπ : ‚Ñù) ‚â† 0 := Nat.cast_ne_zero.mpr Fintype.card_ne_zero
    field_simp
  rw [‚Üê hval]
  apply Continuous.tendsto
  -- entropy(softmax s Œ±) = -‚àë i, softmax(i) * log(softmax(i))
  -- Each softmax component is continuous in Œ±, and x * log x is continuous
  unfold entropy
  apply Continuous.neg; apply continuous_finset_sum; intro i _
  have hcont_sm : Continuous (fun Œ± => softmax s Œ± i) := by
    simp only [softmax]
    exact (continuous_exp.comp (continuous_mul_right (s i))).div
      (continuous_finset_sum _ (fun j _ => continuous_exp.comp (continuous_mul_right (s j))))
      (fun Œ± => partitionFn_ne_zero s Œ±)
  have hcont_log : Continuous (fun Œ± => Real.log (softmax s Œ± i)) :=
    Real.continuousOn_log.comp_continuous hcont_sm (fun Œ± => ne_of_gt (softmax_pos s Œ± i))
  exact hcont_sm.mul hcont_log

/-- As Œ± ‚Üí ‚àû (with unique max), entropy approaches 0. -/
theorem entropy_tendsto_zero [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_unique : ‚àÄ j, j ‚â† i_max ‚Üí s j < s i_max) :
    Tendsto (Œª Œ± => entropy (softmax s Œ±)) atTop (ùìù 0) := by
  -- entropy p = ‚àë i, negMulLog(p i), and negMulLog is continuous
  -- softmax(i) ‚Üí (if i = i_max then 1 else 0), negMulLog(0) = negMulLog(1) = 0
  -- So each term ‚Üí 0, and the finite sum ‚Üí 0
  have hrewrite : (fun Œ± => entropy (softmax s Œ±)) =
      fun Œ± => ‚àë i, Real.negMulLog (softmax s Œ± i) := by
    ext Œ±; unfold entropy Real.negMulLog
    simp only [neg_mul, Finset.sum_neg_distrib, neg_neg]
  rw [hrewrite, show (0 : ‚Ñù) = ‚àë _i : Œπ, (0 : ‚Ñù) from by simp]
  apply tendsto_finset_sum; intro i _
  -- negMulLog(softmax s Œ± i) ‚Üí negMulLog(limit_i) = 0
  have hlim := tendsto_softmax_infty_unique_max s i_max h_unique i
  have hval : Real.negMulLog (if i = i_max then 1 else 0) = 0 := by
    split_ifs <;> simp
  rw [‚Üê hval]
  exact (Real.continuous_negMulLog.tendsto _).comp hlim

/-- Exponential rate of concentration. -/
theorem softmax_exponential_decay [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_max : ‚àÄ j, s j ‚â§ s i_max) (i : Œπ) (hi : s i < s i_max) :
    ‚àÉ C > 0, ‚àÄ Œ± > 0, softmax s Œ± i ‚â§ C * exp (-Œ± * (s i_max - s i)) := by
  use 1
  constructor
  ¬∑ exact one_pos
  ¬∑ intro Œ± _
    -- softmax i = softmax i_max * exp(Œ±(s_i - s_i_max))
    have hratio := softmax_ratio s Œ± i i_max
    rw [hratio]
    have hle : softmax s Œ± i_max ‚â§ 1 := softmax_le_one s Œ± i_max
    calc softmax s Œ± i_max * exp (Œ± * (s i - s i_max))
        ‚â§ 1 * exp (Œ± * (s i - s i_max)) := by
            apply mul_le_mul_of_nonneg_right hle (le_of_lt (exp_pos _))
      _ = exp (Œ± * (s i - s i_max)) := one_mul _
      _ = exp (-(Œ± * (s i_max - s i))) := by ring_nf
      _ = exp (-Œ± * (s i_max - s i)) := by ring_nf
      _ = 1 * exp (-Œ± * (s i_max - s i)) := (one_mul _).symm

/-- For practical computation: when is softmax close enough to hardmax? -/
theorem softmax_negligible [Nonempty Œπ] (s : Œπ ‚Üí ‚Ñù)
    (i_max : Œπ) (h_max : ‚àÄ j, s j ‚â§ s i_max) (Œµ : ‚Ñù) (hŒµ : 0 < Œµ)
    (gap : ‚Ñù) (hgap : 0 < gap) (h_gap_bound : ‚àÄ j, j ‚â† i_max ‚Üí s i_max - s j ‚â• gap) :
    ‚àÄ Œ±, Œ± > (1/gap) * |log Œµ| ‚Üí
      ‚àÄ j, j ‚â† i_max ‚Üí softmax s Œ± j < Œµ := by
  intro Œ± hŒ± j hj
  have hgap_j : s i_max - s j ‚â• gap := h_gap_bound j hj
  have hsj : s j < s i_max := by linarith
  have hŒ±_pos : 0 < Œ± := by
    have h : 0 ‚â§ (1/gap) * |log Œµ| := by positivity
    linarith
  -- Direct bound: softmax j = softmax i_max * exp(Œ±(s_j - s_i_max)) ‚â§ exp(-Œ± * gap)
  have hratio := softmax_ratio s Œ± j i_max
  have hle_max : softmax s Œ± i_max ‚â§ 1 := softmax_le_one s Œ± i_max
  have hbound : softmax s Œ± j ‚â§ exp (-Œ± * (s i_max - s j)) := by
    rw [hratio]
    calc softmax s Œ± i_max * exp (Œ± * (s j - s i_max))
        ‚â§ 1 * exp (Œ± * (s j - s i_max)) := by
            apply mul_le_mul_of_nonneg_right hle_max (le_of_lt (exp_pos _))
      _ = exp (Œ± * (s j - s i_max)) := one_mul _
      _ = exp (-Œ± * (s i_max - s j)) := by ring_nf
  -- softmax j ‚â§ exp(-Œ± * (s i_max - s j)) ‚â§ exp(-Œ± * gap)
  have hexp_mono : exp (-Œ± * (s i_max - s j)) ‚â§ exp (-Œ± * gap) := by
    apply exp_le_exp.mpr
    have : -Œ± * (s i_max - s j) ‚â§ -Œ± * gap := by
      apply mul_le_mul_of_nonpos_left hgap_j
      linarith
    exact this
  -- exp(-Œ± * gap) < Œµ when Œ± > (1/gap) * |log Œµ|
  have hexp_lt : exp (-Œ± * gap) < Œµ := by
    rw [‚Üê exp_log hŒµ]
    apply exp_lt_exp.mpr
    have h1 : Œ± * gap > |log Œµ| := by
      have : Œ± > (1/gap) * |log Œµ| := hŒ±
      calc Œ± * gap > (1/gap) * |log Œµ| * gap := by nlinarith
        _ = |log Œµ| := by field_simp
    by_cases hŒµ1 : Œµ < 1
    ¬∑ have hlog_neg : log Œµ < 0 := log_neg hŒµ hŒµ1
      have habs : |log Œµ| = -log Œµ := abs_of_neg hlog_neg
      rw [habs] at h1
      linarith
    ¬∑ push_neg at hŒµ1
      have hlog_nonneg : 0 ‚â§ log Œµ := log_nonneg hŒµ1
      have habs : |log Œµ| = log Œµ := abs_of_nonneg hlog_nonneg
      rw [habs] at h1
      have : -Œ± * gap < 0 := by linarith
      linarith
  calc softmax s Œ± j ‚â§ exp (-Œ± * (s i_max - s j)) := hbound
    _ ‚â§ exp (-Œ± * gap) := hexp_mono
    _ < Œµ := hexp_lt

end Softmax
